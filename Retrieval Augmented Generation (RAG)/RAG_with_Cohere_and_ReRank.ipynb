{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "11b52622-f38a-4b3a-a916-c73619babb48",
      "metadata": {
        "id": "11b52622-f38a-4b3a-a916-c73619babb48"
      },
      "source": [
        "# Improving Retrieval Performance by Reranker models\n",
        "\n",
        "This notebook showcases how to do a two-stage pass for retrieval. Use `embedding-based` retrieval with a high `top-k` value\n",
        "in order to maximize recall and get a large set of candidate items. Then, use `LLM-based` retrieval\n",
        "to dynamically select the nodes that are actually relevant to the query."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip install cohere"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTET79KuDP8z",
        "outputId": "8b58b8f6-21a4-47fc-bdc8-7a3d2c5f018f"
      },
      "id": "RTET79KuDP8z",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cohere\n",
            "  Downloading cohere-5.5.8-py3-none-any.whl (173 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.8/173.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3<2.0.0,>=1.34.0 (from cohere)\n",
            "  Downloading boto3-1.34.143-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Downloading fastavro-1.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.21.2 (from cohere)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx-sse<0.5.0,>=0.4.0 (from cohere)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Collecting parameterized<0.10.0,>=0.9.0 (from cohere)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.19.1)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Downloading types_requests-2.32.0.20240622-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (4.12.2)\n",
            "Collecting botocore<1.35.0,>=1.34.143 (from boto3<2.0.0,>=1.34.0->cohere)\n",
            "  Downloading botocore-1.34.143-py3-none-any.whl (12.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.34.0->cohere)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.34.0->cohere)\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.21.2->cohere)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.21.2->cohere)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (2.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.0.7)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere) (0.23.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.143->boto3<2.0.0,>=1.34.0->cohere) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.66.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.143->boto3<2.0.0,>=1.34.0->cohere) (1.16.0)\n",
            "Installing collected packages: types-requests, parameterized, jmespath, httpx-sse, h11, fastavro, httpcore, botocore, s3transfer, httpx, boto3, cohere\n",
            "Successfully installed boto3-1.34.143 botocore-1.34.143 cohere-5.5.8 fastavro-1.9.5 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 httpx-sse-0.4.0 jmespath-1.0.1 parameterized-0.9.0 s3transfer-0.10.2 types-requests-2.32.0.20240622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qqq llama-index llama-hub cohere langchain openai accelerate==0.21.0 bitsandbytes==0.40.2 transformers sentence_transformers InstructorEmbedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lQOVGlEyHbP",
        "outputId": "742843c2-4a0b-4880-e1e9-a73a4e44bde4"
      },
      "id": "0lQOVGlEyHbP",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.9/103.9 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.8/173.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.6/983.6 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.9/357.9 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for html2text (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain sentence-transformers chromadb langchainhub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMn6P1Hss1d6",
        "outputId": "5a5cc54e-6aec-4d22-d703-4c2895b15631"
      },
      "id": "eMn6P1Hss1d6",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.5.4-py3-none-any.whl (581 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.4/581.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchainhub\n",
            "  Downloading langchainhub-0.1.20-py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.13)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.85)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.41.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.1)\n",
            "Collecting chroma-hnswlib==0.7.5 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.64.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.12.3)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.6)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.0)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (24.1)\n",
            "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (2.32.0.20240622)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (3.1.4)\n",
            "Collecting python-multipart>=0.0.7 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain) (1.33)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Collecting importlib-metadata<=7.1,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl (29 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.5.82)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (13.7.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.19.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb) (2.1.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain) (3.0.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=9bce3f30b4fb531d3031b448107e1fec79f79b962129bd3f92c84e875c895941\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, uvicorn, ujson, python-multipart, python-dotenv, overrides, opentelemetry-util-http, opentelemetry-proto, importlib-metadata, humanfriendly, httptools, dnspython, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, langchainhub, email_validator, coloredlogs, opentelemetry-semantic-conventions, opentelemetry-instrumentation, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation-asgi, fastapi-cli, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, fastapi, chromadb\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.0.0\n",
            "    Uninstalling importlib_metadata-8.0.0:\n",
            "      Successfully uninstalled importlib_metadata-8.0.0\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.3 chroma-hnswlib-0.7.5 chromadb-0.5.4 coloredlogs-15.0.1 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.0 fastapi-cli-0.0.4 httptools-0.6.1 humanfriendly-10.0 importlib-metadata-7.1.0 kubernetes-30.1.0 langchainhub-0.1.20 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.18.1 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-instrumentation-0.46b0 opentelemetry-instrumentation-asgi-0.46b0 opentelemetry-instrumentation-fastapi-0.46b0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 opentelemetry-util-http-0.46b0 overrides-7.7.0 posthog-3.5.0 pypika-0.48.9 python-dotenv-1.0.1 python-multipart-0.0.9 starlette-0.37.2 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install langchain_community\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO0p8ofKvNsq",
        "outputId": "136f5557-b288-4fe5-fa00-b2a6e5a042e2"
      },
      "id": "gO0p8ofKvNsq",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.7-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.7)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.13)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.85)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.7->langchain_community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.7->langchain_community) (2.8.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain_community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain_community) (2.20.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Installing collected packages: langchain_community\n",
            "Successfully installed langchain_community-0.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
        "\n",
        "import json\n",
        "import torch\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "# pd.set_option(\"display.max_colwidth\", -1)\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "# transformers\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "# llama_index\n",
        "from llama_index.core.prompts import PromptTemplate\n",
        "from llama_index.core import download_loader, Document, VectorStoreIndex, ServiceContext\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.core.postprocessor import LLMRerank\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "from llama_index.core.response.notebook_utils import display_source_node\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from IPython.display import Markdown, display, HTML\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core.schema import QueryBundle\n",
        "from llama_index.core.indices.postprocessor import SentenceTransformerRerank\n"
      ],
      "metadata": {
        "id": "_1nsoLRYyhNq"
      },
      "id": "_1nsoLRYyhNq",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install -q cohere llama-index-postprocessor-cohere-rerank\n"
      ],
      "metadata": {
        "id": "5W37gTRQvH63"
      },
      "id": "5W37gTRQvH63",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.llamaindex.ai/en/stable/examples/node_postprocessor/SentenceTransformerRerank/"
      ],
      "metadata": {
        "id": "wu_6FXSiwzSW"
      },
      "id": "wu_6FXSiwzSW"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Re-rank\n",
        "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
        "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IK5yjMIJvDdK"
      },
      "id": "IK5yjMIJvDdK",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-llms-huggingface"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8oFjALD0x4O",
        "outputId": "210995ef-03ba-4122-c42f-20a64dadae26"
      },
      "id": "p8oFjALD0x4O",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-llms-huggingface\n",
            "  Downloading llama_index_llms_huggingface-0.2.4-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: huggingface-hub<0.24.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (0.23.4)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.41 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (0.10.53.post1)\n",
            "Collecting text-generation<0.8.0,>=0.7.0 (from llama-index-llms-huggingface)\n",
            "  Downloading text_generation-0.7.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (2.3.0+cu121)\n",
            "Requirement already satisfied: transformers[torch]<5.0.0,>=4.37.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.12.2)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.0.8)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.27.0)\n",
            "Requirement already satisfied: llama-cloud<0.0.7,>=0.0.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.0.6)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.35.13)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (9.4.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (8.4.2)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.7.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.14.1)\n",
            "Requirement already satisfied: pydantic<3,>2 in /usr/local/lib/python3.10/dist-packages (from text-generation<0.8.0,>=0.7.0->llama-index-llms-huggingface) (2.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.12.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.5.82)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.4.3)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.21.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (4.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.4.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>2->text-generation<0.8.0,>=0.7.0->llama-index-llms-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>2->text-generation<0.8.0,>=0.7.0->llama-index-llms-huggingface) (2.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.21.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.16.0)\n",
            "Installing collected packages: text-generation, llama-index-llms-huggingface\n",
            "Successfully installed llama-index-llms-huggingface-0.2.4 text-generation-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.huggingface import HuggingFaceLLM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhLLwjtKtnsP",
        "outputId": "bd206d6d-6fb5-4821-b112-00dec9f658de"
      },
      "id": "dhLLwjtKtnsP",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "1. In this section we will work with the QLoRA paper and create an initial set of nodes (chunk size 512).\n",
        "2. We will use Open Source LLM [`zephyr-7b-alpha`](https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha) and embedding [`hkunlp/instructor-large`](https://huggingface.co/hkunlp/instructor-large)"
      ],
      "metadata": {
        "id": "jXhpbxHuyQVT"
      },
      "id": "jXhpbxHuyQVT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "cg0vTaLvBvYY"
      },
      "id": "cg0vTaLvBvYY"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/LLM\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4mTdkHpw5mg",
        "outputId": "d73ad60a-4518-4fed-c542-b73bc49f0d7f"
      },
      "id": "P4mTdkHpw5mg",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /LLM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "a07c0e42-1ae8-4267-9355-6bb75323f82a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f4b486e-db6e-41dc-d3df-068a7c371595"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-94b1f44eb193>:1: DeprecationWarning: Call to deprecated function (or staticmethod) download_loader. (`download_loader()` is deprecated. Please install tool using pip install directly instead.)\n",
            "  PDFReader = download_loader(\"PDFReader\")\n"
          ]
        }
      ],
      "source": [
        "PDFReader = download_loader(\"PDFReader\")\n",
        "loader = PDFReader()\n",
        "docs = loader.load_data(file=Path(\"/LLM/MyDrive/RAG/Qlora.pdf\"))"
      ],
      "id": "a07c0e42-1ae8-4267-9355-6bb75323f82a"
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.node_parser import SimpleNodeParser\n",
        "node_parser = SimpleNodeParser.from_defaults(chunk_size=512)\n",
        "nodes = node_parser.get_nodes_from_documents(docs)"
      ],
      "metadata": {
        "id": "mMMSWgPKGn9T"
      },
      "id": "mMMSWgPKGn9T",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nodes[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyv7xCp39exF",
        "outputId": "8da08d78-7810-4a34-9525-3a03fbe293c4"
      },
      "id": "cyv7xCp39exF",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextNode(id_='f30cd62a-c9fb-435d-a80b-e3674411ab00', embedding=None, metadata={'page_label': '1', 'file_name': 'Qlora.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='124f53e8-af63-438a-b5d5-95b83a89fd2d', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '1', 'file_name': 'Qlora.pdf'}, hash='ccf1895a3cd48cab967775a8b1b159b39eceb0307b2e3afed5be7e80da928c33'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2ffad800-6a1d-48ac-a8b9-b73d17b1a3be', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5fb03aa5eedbf5806ef0619366f82d0880ac1d1e38c70b16a44372fa860f38a4')}, text='QL ORA: Efficient Finetuning of Quantized LLMs\\nTim Dettmers∗Artidoro Pagnoni∗Ari Holtzman\\nLuke Zettlemoyer\\nUniversity of Washington\\n{dettmers,artidoro,ahai,lsz}@cs.washington.edu\\nAbstract\\nWe present QLORA, an efficient finetuning approach that reduces memory us-\\nage enough to finetune a 65B parameter model on a single 48GB GPU while\\npreserving full 16-bit finetuning task performance. QLORAbackpropagates gradi-\\nents through a frozen, 4-bit quantized pretrained language model into Low Rank\\nAdapters (LoRA). Our best model family, which we name Guanaco , outperforms\\nall previous openly released models on the Vicuna benchmark, reaching 99.3%\\nof the performance level of ChatGPT while only requiring 24 hours of finetuning\\non a single GPU. QLORAintroduces a number of innovations to save memory\\nwithout sacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that\\nis information theoretically optimal for normally distributed weights (b) Double\\nQuantization to reduce the average memory footprint by quantizing the quantization\\nconstants, and (c) Paged Optimizers to manage memory spikes. We use QLORA\\nto finetune more than 1,000 models, providing a detailed analysis of instruction\\nfollowing and chatbot performance across 8 instruction datasets, multiple model\\ntypes (LLaMA, T5), and model scales that would be infeasible to run with regular\\nfinetuning (e.g. 33B and 65B parameter models). Our results show that QLoRA\\nfinetuning on a small high-quality dataset leads to state-of-the-art results, even\\nwhen using smaller models than the previous SoTA. We provide a detailed analysis\\nof chatbot performance based on both human and GPT-4 evaluations showing that\\nGPT-4 evaluations are a cheap and reasonable alternative to human evaluation. Fur-\\nthermore, we find that current chatbot benchmarks are not trustworthy to accurately\\nevaluate the performance levels of chatbots. A lemon-picked analysis demonstrates\\nwhere Guanaco fails compared to ChatGPT.', mimetype='text/plain', start_char_idx=0, end_char_idx=1967, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(nodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVYtpa05Gn4X",
        "outputId": "dd88340b-e093-4a8b-967c-61d3ec55ef97"
      },
      "id": "hVYtpa05Gn4X",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "zsdSXG0SMHgF"
      },
      "id": "zsdSXG0SMHgF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbIdDgkPu9U8"
      },
      "source": [
        "## LLM (`zephyr-7b-alpha`)"
      ],
      "id": "wbIdDgkPu9U8"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import os\n",
        "# from huggingface_hub import login\n",
        "# access_token='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'\n",
        "# HUGGINGFACE_TOKEN = os.environ.get(access_token)\n",
        "# login(token=HUGGINGFACE_TOKEN)\n"
      ],
      "metadata": {
        "id": "8Gte049yyWJJ"
      },
      "id": "8Gte049yyWJJ",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import cohere\n",
        "import os\n",
        "import getpass\n",
        "os.environ[\"TrpJilIKyuyf1jFx9ju9rtj6XDsaU687CcUODNzW\"] = os.getenv(\"COHERE_API_KEY\") or getpass.getpass()\n",
        "# init client\n",
        "cohere_api_key = cohere.Client(os.environ[\"TrpJilIKyuyf1jFx9ju9rtj6XDsaU687CcUODNzW\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JY9hTR8y55p",
        "outputId": "3c9ff9ee-3a5b-487e-c337-243b2a3c7431"
      },
      "id": "-JY9hTR8y55p",
      "execution_count": 17,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "6cd91eb1f346430a97ac81b424652341",
            "466d746d756942368084109c946a1517",
            "4257b45badd44a5eb8c13fcc137643bd",
            "1108b8643bd440f3a79636e2c28e1a2f",
            "c448eb1f10514b029cfd93638f453445",
            "780853b2806c4b8ba48c5148d5634149",
            "ceb3aa94463f4f5a8a6efd88cde51d16",
            "f738edf27b954424b9cb859d087b44a6",
            "c5fd61db1f8b414a8814c931d6529973",
            "86447ad506bc427597871bbdedc01039",
            "df86f5a3b9944748b061ca9296f452d3"
          ]
        },
        "id": "cEzfJJYJZZHa",
        "outputId": "04881cf5-d67b-463a-c413-6c551e880252"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cd91eb1f346430a97ac81b424652341"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# huggingface and cohere api token\n",
        "# hf_token = userdata.get('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')\n",
        "# cohere_api_key = userdata.get('TrpJilIKyuyf1jFx9ju9rtj6XDsaU687CcUODNzW')\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "\n",
        "def messages_to_prompt(messages):\n",
        "  prompt = \"\"\n",
        "  for message in messages:\n",
        "    if message.role == 'system':\n",
        "      prompt += f\"<|system|>\\n{message.content}</s>\\n\"\n",
        "    elif message.role == 'user':\n",
        "      prompt += f\"<|user|>\\n{message.content}</s>\\n\"\n",
        "    elif message.role == 'assistant':\n",
        "      prompt += f\"<|assistant|>\\n{message.content}</s>\\n\"\n",
        "\n",
        "  # ensure we start with a system prompt, insert blank if needed\n",
        "  if not prompt.startswith(\"<|system|>\\n\"):\n",
        "    prompt = \"<|system|>\\n</s>\\n\" + prompt\n",
        "\n",
        "  # add final assistant prompt\n",
        "  prompt = prompt + \"<|assistant|>\\n\"\n",
        "\n",
        "  return prompt\n",
        "\n",
        "\n",
        "llm = HuggingFaceLLM(\n",
        "    model_name=\"HuggingFaceH4/zephyr-7b-alpha\",\n",
        "    tokenizer_name=\"HuggingFaceH4/zephyr-7b-alpha\",\n",
        "    query_wrapper_prompt=PromptTemplate(\"<|system|>\\n</s>\\n<|user|>\\n{query_str}</s>\\n<|assistant|>\\n\"),\n",
        "    context_window=3900,\n",
        "    max_new_tokens=256,\n",
        "    model_kwargs={\"quantization_config\": quantization_config},\n",
        "    # tokenizer_kwargs={},\n",
        "    generate_kwargs={\"temperature\": 0.7, \"top_k\": 50, \"top_p\": 0.95},\n",
        "    messages_to_prompt=messages_to_prompt,\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "id": "cEzfJJYJZZHa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding (`hkunlp/instructor-large`)"
      ],
      "metadata": {
        "id": "BaEuR2h6MN--"
      },
      "id": "BaEuR2h6MN--"
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/PromtEngineer/localGPT/issues/722"
      ],
      "metadata": {
        "id": "qOaNly326WLe"
      },
      "id": "qOaNly326WLe"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers==2.2.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZyz6Nhz25px",
        "outputId": "4212f613-8bb9-4b54-ceb9-6349e69d4e07"
      },
      "id": "vZyz6Nhz25px",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers==2.2.2 in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (4.41.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (0.18.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (0.23.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->sentence-transformers==2.2.2) (12.5.82)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.4.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.2) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==2.2.2) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers==2.2.2) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d-7C9yUf5wOk"
      },
      "id": "d-7C9yUf5wOk",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from InstructorEmbedding import INSTRUCTOR\n",
        "# model = INSTRUCTOR('hkunlp/instructor-large')\n",
        "# sentence = \"3D ActionSLAM: wearable person tracking in multi-floor environments\"\n",
        "# instruction = \"Represent the Science title:\"\n",
        "# embeddings = model.encode([[instruction,sentence]])\n",
        "# print(embeddings)\n"
      ],
      "metadata": {
        "id": "KLWwrcw35g9S"
      },
      "id": "KLWwrcw35g9S",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkiNIkcdV0F4",
        "outputId": "5377aaf3-ae59-420d-c666-563c295567e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load INSTRUCTOR_Transformer\n",
            "max_seq_length  512\n"
          ]
        }
      ],
      "source": [
        "# DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "embed_model = HuggingFaceInstructEmbeddings(\n",
        "    model_name=\"hkunlp/instructor-large\"\n",
        ")"
      ],
      "id": "pkiNIkcdV0F4"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-embeddings-langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W1qgiID7r4f",
        "outputId": "21bb9748-cbf4-40bf-8e88-10ef362ae397"
      },
      "id": "5W1qgiID7r4f",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-embeddings-langchain\n",
            "  Downloading llama_index_embeddings_langchain-0.1.2-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-langchain) (0.10.53.post1)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.27.0)\n",
            "Requirement already satisfied: llama-cloud<0.0.7,>=0.0.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.0.6)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.35.13)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (8.4.2)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.14.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (4.0.3)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llama-cloud<0.0.7,>=0.0.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.8.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2024.5.15)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.2.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (24.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.16.0)\n",
            "Installing collected packages: llama-index-embeddings-langchain\n",
            "Successfully installed llama-index-embeddings-langchain-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlEgVqRQgZRr"
      },
      "source": [
        "## Configure Index and Retriever"
      ],
      "id": "XlEgVqRQgZRr"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "PZl7SgPCVrg5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "479f0704-3c20-4746-a795-3e970bdde332"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-7b0233087e6a>:2: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
            "  service_context = ServiceContext.from_defaults(llm=llm,\n"
          ]
        }
      ],
      "source": [
        "# ServiceContext\n",
        "service_context = ServiceContext.from_defaults(llm=llm,\n",
        "                                               embed_model=embed_model\n",
        "                                               )\n",
        "\n",
        "# index\n",
        "vector_index = VectorStoreIndex(\n",
        "    nodes, service_context=service_context\n",
        ")\n",
        "\n",
        "# configure retriever\n",
        "retriever = VectorIndexRetriever(\n",
        "    index=vector_index,\n",
        "    similarity_top_k=10,\n",
        "    service_context=service_context)"
      ],
      "id": "PZl7SgPCVrg5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f757e90-3f95-4c1d-ba2a-e172a0fd7645"
      },
      "source": [
        "## Initialize Re-rankers"
      ],
      "id": "4f757e90-3f95-4c1d-ba2a-e172a0fd7645"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "aab9d1ec-2ca4-4cd3-bd8b-0dde31f51d73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456,
          "referenced_widgets": [
            "e8b5702cde8140598ce9c73c85599de8",
            "1d13a883472a4933888c0a2bf9170cf2",
            "d0c2df989f3746f7b9b3d945cd5e8901",
            "521e5438e02c436cb8a955eedd19a773",
            "6a081b2a674545b1b9253873cf0424e9",
            "1983243301a74b908f3af3ab791ad858",
            "8f8a79d41bf845d3ab85c62d5ed7154b",
            "5a51b59565294b4a90d8929b72227965",
            "a12c2ed09bc249a5b145fb2573850c58",
            "7b3eb63afbd540eaa9cf0403444545f3",
            "f37892182d87496bb94dabb93d3c2d36",
            "7c4c183a8f40471aa028480d317c5a32",
            "8c11fbd2e1d44a4bbf7ce85efa9469a7",
            "0b884583612c42e99d9337fb037c4118",
            "61c6b26f7bc34791a299b91c2e311948",
            "3af81d3617fe4ffb8b038b2ee87661cc",
            "513bcc7c370240f6a30e75cee64f7977",
            "ae54e97c5a704fb98f83ecc20df9d2b7",
            "4f8767799a194fe7852d981cd98d56f1",
            "b35e7ea0d9e04a25926f43c848c3b71c",
            "b6b8306b6b0049d4b27cb7a1d5bdf3a7",
            "0bcca2c260ce487caebbf978311bcc16",
            "86c0b9a0dc0544e89f1c2fa4d19a2d18",
            "8ffc3a4f10f84afd92b1d32f22c43da8",
            "c3427192dbe64cf492c884b4dad2aa36",
            "9e75eac4076744d6b3ce08b1f988ee5a",
            "2225ac7b7eac40c1a4fca0a79f4325b1",
            "b35314aa37034005bf273a5012a32de2",
            "9554e83fa9b946288bc9c247ccdddd38",
            "08e9888223364bb3b3acd41fcdd37a74",
            "b24116fbbb904e179f08875fa4399fad",
            "164812204d91499898b08e96ff390774",
            "e7d6d06eaef44baaa9f7b71a45e827aa",
            "9f2a7b332fec4d95b52518c02ba39374",
            "a4ec0c1e1ef242128e82e1b4d15752a5",
            "747e87fc3b63481e92081e9dfd40579a",
            "f5b4ef07b5c344e08749282eb777e91e",
            "bf59aa0a707f456d8020ed6c0bb4985a",
            "e5477792a46c457d9f96a8e2303f13c1",
            "7f8c9ee6207d4620a4224bd177ed430f",
            "100c18c7c3814d33a2217f80dc20d866",
            "a698ccf81c6b469b84e22d5a752fa849",
            "17cd695ae88a45c6afb707087bc7c428",
            "edfae701958f41098ee8156500d828f1",
            "79171873c19040e580875e524204dea4",
            "8b684c1b04b446cbbed227d4e4afd452",
            "69407250b52d421a8c4c0c7bd24219cf",
            "49beced1ee644cbb9c9dd44411758851",
            "57eb33d0270a41d9865ac5e444e93a32",
            "6c9236001b284c85aee46dfbbf060706",
            "a2b729158c754a7a902b6b78715291b7",
            "ce24cdc70fde481e86071fd1caab9813",
            "5c9eb001a181410fb93f3f11a616676d",
            "a4066819993e4b96aa8f44eaaf6a0846",
            "7df8d4294dcf40b8b38ccf68b4930807",
            "606f2bad18354d84a0c27bb1199f3a92",
            "ff64d8a5ca664c2a9e2f5509e548c015",
            "63f50e8ee94a4d569714c018fa669b17",
            "30fe51ce05c6488ca1d6054a285d6dca",
            "86cc62ab92574385834347b7b24f559a",
            "8c643f99cca64a7bb4582006e77a2bd2",
            "0148c7b036b74af6aa7ad7d7785229d7",
            "5ec85ff2fd284676831a2210c0999b55",
            "0da6ebf910b54ed4bf8e7e5f4ebf4cc7",
            "d11f79442a9a4a3f9b04a28fbc11b01d",
            "d905ffe85a7e4e568205aed7296289cb",
            "ad6eef18310d4717b64d153856fb7e21",
            "6b1be45b68f546ffa0d2c226ecd9f3a6",
            "1710e88ceefc4d078225bcec8e8a7e98",
            "59ff7cb07a064a04928fa3cae4407f01",
            "34efbc0dd59f4dd288ae67766c859c52",
            "4f2b611c1ae0428ca5351ca0a582c832",
            "f49bb7987c88474ea102c02687cc7bd4",
            "ecd14d0567e04020ac5630e77e0ba622",
            "237786aa999d43479d08e55a3f7c37a7",
            "62e1910678404be39d65507aefb4a579",
            "33bbcbb393eb489488cd6de8e98e0090",
            "ab9b6001d5704afe8e96fa1072ccb42b",
            "8c0f507418054355b3d31b31b5980caf",
            "2671e58e93b446ec995ca1fa735fcd22",
            "280a8e8fc6544d3292c2767acb7d4a12",
            "cd3d4b4e5ae84b5db2111d9e503ddf7d",
            "56e7869ed4354237b7435fdefac71461",
            "4166f2a005714a868c26f0d10ce507ba",
            "2b57ba63c10e43a6a856b14caae0fe44",
            "e331768dd150484ab2dfc387268f0c8d",
            "65798d204ec54b589cf777236d12f909",
            "06fc346daeac4e5bbf46c5abc9c67263",
            "adddc443c55c490aa1fac0a1dc2c2e89",
            "9aa3d3bbaaa04940a27844fc66e9cf60",
            "d5c4e5475ed248d3a23b1a0b56a0a7d3",
            "a0260b9f2b1b4bafb66bda19b9e245ea",
            "9ae0ae52878947f699187cf1a745a8b6",
            "1aed6cce195a4752a089b2c305e1d8ce",
            "7d5e4b4d06c841ed8dcd959b706de012",
            "5e8d2a184be7466c9db428061062506d",
            "4d04085c2e1241a7b6df4ea8a15c877d",
            "4ec97a247a8846e3a34ab730319c9e2e",
            "c5f3577fa52d4b39bbf12a2d1d777825",
            "2748a653ad2c4c57b6c350e83001965a",
            "15b91e39c2ff45c084d2296b847655bf",
            "9444d49b94f44f7e885379dd3b4579be",
            "fd2094d9a20a40458e0c3416b65480f8",
            "4b9aac73477b45c6b1bd83eadf9095b7",
            "d744f9661f3f4a0aa96b6269b89b5b8e",
            "e6b82c8687f64b8abe7e18d80260ff1c",
            "7ee15f468d2e49b0a0b7d6940e057f7b",
            "1dcfd55096e04bf58144ef4616256ad1",
            "82e599fd460d4ba1afeeb60a9901be58",
            "4673c726899c446583e8c5313c2bd494",
            "18225f843322455cbfadfb3926f0df72",
            "f510bcc96c7e4413b31d0262217cc392",
            "2dc1d04f6f20458a931ae4f7a9913fee",
            "2f130a82737d459880b49fd6868332df",
            "6326694600054549a36232183e2cee18",
            "621e249dd863495cb5d88c44f9919f2d",
            "44e637d4bb394305ab2a4ed9b7f260b2",
            "d37ae8a0b8ff44ba9435e85ee12a0d34",
            "56bbbf97c7424aa79ae1f6ec513d8fdb",
            "e46cedd83cef40d58b6229c27d924bf2",
            "d90c2fbdb6ed400cbef6e355fa77290e",
            "268381e8055a4b79a1faf91e6f6254f5",
            "a533fcb0fe7b4f4aa96ea2f1b3e92fde",
            "f28e5b45e9614ac984d665aaeb2778e1",
            "76a6fd497a57449f934f18d7b46a245a",
            "68016e2fc2334e918a726530bd55e0a0",
            "5bc9ef7863dc4502ab4abec128a769c2",
            "0bc811d59c374d3a93f80cd1a67be92a",
            "fbb7d85b43ef48f3a2ed6e31ccb3c9cd",
            "7669aad1d1f84a27b55deaf01fed88c3",
            "dd7bf50fea2f471b9b07afa111e96994",
            "657ca0cf84c04a4fadad8d7ec4c20aae"
          ]
        },
        "outputId": "eb855488-9942-46ec-96ae-7d10b8fcdb16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/799 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8b5702cde8140598ce9c73c85599de8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c4c183a8f40471aa028480d317c5a32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86c0b9a0dc0544e89f1c2fa4d19a2d18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f2a7b332fec4d95b52518c02ba39374"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79171873c19040e580875e524204dea4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "606f2bad18354d84a0c27bb1199f3a92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/801 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad6eef18310d4717b64d153856fb7e21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab9b6001d5704afe8e96fa1072ccb42b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "adddc443c55c490aa1fac0a1dc2c2e89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2748a653ad2c4c57b6c350e83001965a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18225f843322455cbfadfb3926f0df72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "268381e8055a4b79a1faf91e6f6254f5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# cohere_api_key = userdata.get('TrpJilIKyuyf1jFx9ju9rtj6XDsaU687CcUODNzW')\n",
        "# Define all embeddings and rerankers\n",
        "RERANKERS = {\n",
        "    \"WithoutReranker\": \"None\",\n",
        "    \"CohereRerank\": CohereRerank(api_key=\"TrpJilIKyuyf1jFx9ju9rtj6XDsaU687CcUODNzW\", top_n=5),\n",
        "    \"bge-reranker-base\": SentenceTransformerRerank(model=\"BAAI/bge-reranker-base\", top_n=5),\n",
        "    \"bge-reranker-large\": SentenceTransformerRerank(model=\"BAAI/bge-reranker-large\", top_n=5)\n",
        "}"
      ],
      "id": "aab9d1ec-2ca4-4cd3-bd8b-0dde31f51d73"
    },
    {
      "cell_type": "markdown",
      "id": "7e3d5f23-dfcd-458d-a9d3-dd66de0ab054",
      "metadata": {
        "id": "7e3d5f23-dfcd-458d-a9d3-dd66de0ab054"
      },
      "source": [
        "## Retrieval Comparisons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "47480c6d-8914-4562-a789-fd53a99a7afb",
      "metadata": {
        "id": "47480c6d-8914-4562-a789-fd53a99a7afb"
      },
      "outputs": [],
      "source": [
        "def get_retrieved_nodes(\n",
        "    query_str, reranker\n",
        "):\n",
        "    query_bundle = QueryBundle(query_str)\n",
        "\n",
        "    retrieved_nodes = retriever.retrieve(query_bundle)\n",
        "\n",
        "    if reranker != \"None\":\n",
        "      retrieved_nodes = reranker.postprocess_nodes(retrieved_nodes, query_bundle)\n",
        "    else:\n",
        "        retrieved_nodes\n",
        "\n",
        "    return retrieved_nodes\n",
        "\n",
        "\n",
        "def pretty_print(df):\n",
        "    return display(HTML(df.to_html().replace(\"\\\\n\", \"<br>\")))\n",
        "\n",
        "\n",
        "def visualize_retrieved_nodes(nodes) -> None:\n",
        "    result_dicts = []\n",
        "    for node in nodes:\n",
        "        node = deepcopy(node)\n",
        "        node.node.metadata = None\n",
        "        node_text = node.node.get_text()\n",
        "        node_text = node_text.replace(\"\\n\", \" \")\n",
        "\n",
        "        result_dict = {\"Score\": node.score, \"Text\": node_text}\n",
        "        result_dicts.append(result_dict)\n",
        "\n",
        "    pretty_print(pd.DataFrame(result_dicts))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RERANKERS.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGJbWuczxgtA",
        "outputId": "eeb79322-2c12-4749-e674-beb25f4a439b"
      },
      "id": "EGJbWuczxgtA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('WithoutReranker', 'None'), ('CohereRerank', CohereRerank(callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x7fbeacade170>, model='rerank-english-v2.0', top_n=5)), ('bge-reranker-base', SentenceTransformerRerank(callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x7fbea5994a60>, model='BAAI/bge-reranker-base', top_n=5)), ('bge-reranker-large', SentenceTransformerRerank(callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x7fbea59ee740>, model='BAAI/bge-reranker-large', top_n=5))])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# query_str = \"QLoRA?\"\n",
        "\n",
        "# # Loop over rerankers\n",
        "# for rerank_name, reranker in RERANKERS.items():\n",
        "#     print(f\"Running Evaluation for Reranker: {rerank_name}\")\n",
        "\n",
        "#     query_bundle = QueryBundle(query_str)\n",
        "\n",
        "#     retrieved_nodes = retriever.retrieve(query_bundle)\n",
        "\n",
        "#     if reranker != \"None\":\n",
        "#       retrieved_nodes = reranker.postprocess_nodes(retrieved_nodes, query_bundle)\n",
        "#     else:\n",
        "#         retrieved_nodes\n",
        "\n",
        "#     print(f\"Visualize Retrieved Nodes for Reranker: {rerank_name}\")\n",
        "#     print(\"retrieved_nodes : \",retrieved_nodes)\n",
        "#     visualize_retrieved_nodes(retrieved_nodes)\n"
      ],
      "metadata": {
        "id": "zLW7n68Uj_CE"
      },
      "id": "zLW7n68Uj_CE",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_str = \"What are the top features of QLoRA?\"\n",
        "\n",
        "# Function to validate and clean nodes\n",
        "def clean_nodes(nodes):\n",
        "    cleaned_nodes = []\n",
        "    for node in nodes:\n",
        "        if node.metadata is None:\n",
        "            node.metadata = {}\n",
        "        cleaned_nodes.append(node)\n",
        "    return cleaned_nodes\n",
        "\n",
        "# Loop over rerankers\n",
        "for rerank_name, reranker in RERANKERS.items():\n",
        "    print(f\"Running Evaluation for Reranker: {rerank_name}\")\n",
        "\n",
        "    query_bundle = QueryBundle(query_str)\n",
        "\n",
        "    retrieved_nodes = retriever.retrieve(query_bundle)\n",
        "\n",
        "    # Validate and clean retrieved nodes\n",
        "    retrieved_nodes = clean_nodes(retrieved_nodes)\n",
        "\n",
        "    if reranker != \"None\":\n",
        "        retrieved_nodes = reranker.postprocess_nodes(retrieved_nodes, query_bundle)\n",
        "        # Clean nodes again after reranking\n",
        "        retrieved_nodes = clean_nodes(retrieved_nodes)\n",
        "    else:\n",
        "        retrieved_nodes = clean_nodes(retrieved_nodes)\n",
        "\n",
        "    print(f\"Visualize Retrieved Nodes for Reranker: {rerank_name}\")\n",
        "    for idx, node in enumerate(retrieved_nodes):\n",
        "        print(f\"Node {idx}: {node}\")\n",
        "    # visualize_retrieved_nodes(retrieved_nodes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1niiZ6ME_5Su",
        "outputId": "70b90f29-a5b7-452d-f7b2-81f835125a96"
      },
      "id": "1niiZ6ME_5Su",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Evaluation for Reranker: WithoutReranker\n",
            "Visualize Retrieved Nodes for Reranker: WithoutReranker\n",
            "Node 0: Node ID: 3307edf4-dc70-416a-ab5d-a89f195828d9\n",
            "Text: QL ORA.Using the components described above, we define QLORAfor\n",
            "a single linear layer in the quantized base model with a single LoRA\n",
            "adapter as follows: YBF16=XBF16doubleDequant (cFP32 1, ck-bit 2,WNF4)\n",
            "+XBF16LBF16 1LBF16 2, (5) where doubleDequant (·)is defined as:\n",
            "doubleDequant (cFP32 1, ck-bit 2,Wk-bit) =dequant (dequant (cFP32 1,\n",
            "ck-bit 2),W...\n",
            "Score:  0.874\n",
            "\n",
            "Node 1: Node ID: 9e47c8b4-4807-4957-9d48-f30bb5574c11\n",
            "Text: QLORAhas one low-precision storage data type, in our case\n",
            "usually 4-bit, and one computation data type that is usually BFloat16.\n",
            "In practice, this means whenever a QLORAweight tensor is used, we\n",
            "dequantize the tensor to BFloat16, and then perform a matrix\n",
            "multiplication in 16-bit. We now discuss the components of QL ORA\n",
            "followed by a formal defi...\n",
            "Score:  0.873\n",
            "\n",
            "Node 2: Node ID: 95e0b257-01d5-4ef2-a331-a9a04a229867\n",
            "Text: This second step yields the quantized quantization constants\n",
            "cFP8 2and the second level of quantization constants cFP32 1. We use\n",
            "8-bit Floats with a blocksize of 256 for the second quantization as no\n",
            "performance degradation is observed for 8-bit quantization, in line\n",
            "with results from Dettmers and Zettlemoyer [13]. Since the cFP32 2are\n",
            "positive...\n",
            "Score:  0.870\n",
            "\n",
            "Node 3: Node ID: 43662513-790f-4953-aaac-6d144c55509a\n",
            "Text: QLORAcan be seen as an equalizing factor that helps to close the\n",
            "resource gap between large corporations and small teams with consumer\n",
            "GPUs. Another potential source of impact is deployment to mobile\n",
            "phones. We believe our QLORAmethod might enable the critical milestone\n",
            "of enabling the finetuning of LLMs on phones and other low resource\n",
            "settings...\n",
            "Score:  0.867\n",
            "\n",
            "Node 4: Node ID: 2576d513-ff13-428f-8a70-ebba9a08c280\n",
            "Text: This calls for further investigations of the tradeoffs of simple\n",
            "cross-entropy loss and RLHF training. We hope that QLORA enables such\n",
            "analysis at scale, without the need for overwhelming computational\n",
            "resources. 7 Related Work Quantization of Large Language Models\n",
            "Quantization of LLMs has largely focused on quanti- zation for\n",
            "inference time. Ma...\n",
            "Score:  0.860\n",
            "\n",
            "Node 5: Node ID: 2ff6bec1-82fe-4770-bbe5-dff7dca08d1d\n",
            "Text: Figure 1: Different finetuning methods and their memory\n",
            "requirements. QLORAimproves over LoRA by quantizing the transformer\n",
            "model to 4-bit precision and using paged optimizers to handle memory\n",
            "spikes. 2 Background Block-wise k-bit Quantization Quantization is the\n",
            "process of discretizing an input from a rep- resentation that holds\n",
            "more informatio...\n",
            "Score:  0.859\n",
            "\n",
            "Node 6: Node ID: e408c30c-c74b-4dc2-ac06-979166a339cd\n",
            "Text: Parameter Efficient Finetuning (PEFT) method, most of the memory\n",
            "footprint for LLM finetuning comes from activation gradients and not\n",
            "from the learned LoRA parameters. For a 7B LLaMA model trained on FLAN\n",
            "v2 with a batch size of 1, with LoRA weights equivalent to commonly\n",
            "used 0.2% of the original model weights[ 28,37], the LoRA input\n",
            "gradients ...\n",
            "Score:  0.856\n",
            "\n",
            "Node 7: Node ID: 2718ff40-fc67-4873-9a31-6efa0ba6c364\n",
            "Text: Table 1: Elo ratings for a competition between models, averaged\n",
            "for 10,000 random initial order- ings. The winner of a match is\n",
            "determined by GPT-4 which declares which response is better for a\n",
            "given prompt of the the Vicuna benchmark. 95% confidence intervals are\n",
            "shown ( ±). After GPT- 4, Guanaco 33B and 65B win the most matches,\n",
            "while Guanaco ...\n",
            "Score:  0.855\n",
            "\n",
            "Node 8: Node ID: f01414c7-87ee-4900-bfb2-808e93363b76\n",
            "Text: An additional limitation is that we did not evaluate different\n",
            "bit-precisions, such as using 3-bit base models, or different adapter\n",
            "methods. Besides LoRA, there is also a wide variety Parameter\n",
            "Efficient FineTuning (PEFT) methods that have been shown to work well.\n",
            "However, it is unclear if these methods scale to large models. We used\n",
            "LoRA as ma...\n",
            "Score:  0.854\n",
            "\n",
            "Node 9: Node ID: f30cd62a-c9fb-435d-a80b-e3674411ab00\n",
            "Text: QL ORA: Efficient Finetuning of Quantized LLMs Tim\n",
            "Dettmers∗Artidoro Pagnoni∗Ari Holtzman Luke Zettlemoyer University of\n",
            "Washington {dettmers,artidoro,ahai,lsz}@cs.washington.edu Abstract We\n",
            "present QLORA, an efficient finetuning approach that reduces memory\n",
            "us- age enough to finetune a 65B parameter model on a single 48GB GPU\n",
            "while preserving f...\n",
            "Score:  0.848\n",
            "\n",
            "Running Evaluation for Reranker: CohereRerank\n",
            "Visualize Retrieved Nodes for Reranker: CohereRerank\n",
            "Node 0: Node ID: f30cd62a-c9fb-435d-a80b-e3674411ab00\n",
            "Text: QL ORA: Efficient Finetuning of Quantized LLMs Tim\n",
            "Dettmers∗Artidoro Pagnoni∗Ari Holtzman Luke Zettlemoyer University of\n",
            "Washington {dettmers,artidoro,ahai,lsz}@cs.washington.edu Abstract We\n",
            "present QLORA, an efficient finetuning approach that reduces memory\n",
            "us- age enough to finetune a 65B parameter model on a single 48GB GPU\n",
            "while preserving f...\n",
            "Score:  0.993\n",
            "\n",
            "Node 1: Node ID: 9e47c8b4-4807-4957-9d48-f30bb5574c11\n",
            "Text: QLORAhas one low-precision storage data type, in our case\n",
            "usually 4-bit, and one computation data type that is usually BFloat16.\n",
            "In practice, this means whenever a QLORAweight tensor is used, we\n",
            "dequantize the tensor to BFloat16, and then perform a matrix\n",
            "multiplication in 16-bit. We now discuss the components of QL ORA\n",
            "followed by a formal defi...\n",
            "Score:  0.987\n",
            "\n",
            "Node 2: Node ID: 43662513-790f-4953-aaac-6d144c55509a\n",
            "Text: QLORAcan be seen as an equalizing factor that helps to close the\n",
            "resource gap between large corporations and small teams with consumer\n",
            "GPUs. Another potential source of impact is deployment to mobile\n",
            "phones. We believe our QLORAmethod might enable the critical milestone\n",
            "of enabling the finetuning of LLMs on phones and other low resource\n",
            "settings...\n",
            "Score:  0.986\n",
            "\n",
            "Node 3: Node ID: 95e0b257-01d5-4ef2-a331-a9a04a229867\n",
            "Text: This second step yields the quantized quantization constants\n",
            "cFP8 2and the second level of quantization constants cFP32 1. We use\n",
            "8-bit Floats with a blocksize of 256 for the second quantization as no\n",
            "performance degradation is observed for 8-bit quantization, in line\n",
            "with results from Dettmers and Zettlemoyer [13]. Since the cFP32 2are\n",
            "positive...\n",
            "Score:  0.985\n",
            "\n",
            "Node 4: Node ID: 2718ff40-fc67-4873-9a31-6efa0ba6c364\n",
            "Text: Table 1: Elo ratings for a competition between models, averaged\n",
            "for 10,000 random initial order- ings. The winner of a match is\n",
            "determined by GPT-4 which declares which response is better for a\n",
            "given prompt of the the Vicuna benchmark. 95% confidence intervals are\n",
            "shown ( ±). After GPT- 4, Guanaco 33B and 65B win the most matches,\n",
            "while Guanaco ...\n",
            "Score:  0.985\n",
            "\n",
            "Running Evaluation for Reranker: bge-reranker-base\n",
            "Visualize Retrieved Nodes for Reranker: bge-reranker-base\n",
            "Node 0: Node ID: 95e0b257-01d5-4ef2-a331-a9a04a229867\n",
            "Text: This second step yields the quantized quantization constants\n",
            "cFP8 2and the second level of quantization constants cFP32 1. We use\n",
            "8-bit Floats with a blocksize of 256 for the second quantization as no\n",
            "performance degradation is observed for 8-bit quantization, in line\n",
            "with results from Dettmers and Zettlemoyer [13]. Since the cFP32 2are\n",
            "positive...\n",
            "Score:  0.578\n",
            "\n",
            "Node 1: Node ID: f30cd62a-c9fb-435d-a80b-e3674411ab00\n",
            "Text: QL ORA: Efficient Finetuning of Quantized LLMs Tim\n",
            "Dettmers∗Artidoro Pagnoni∗Ari Holtzman Luke Zettlemoyer University of\n",
            "Washington {dettmers,artidoro,ahai,lsz}@cs.washington.edu Abstract We\n",
            "present QLORA, an efficient finetuning approach that reduces memory\n",
            "us- age enough to finetune a 65B parameter model on a single 48GB GPU\n",
            "while preserving f...\n",
            "Score:  0.425\n",
            "\n",
            "Node 2: Node ID: 9e47c8b4-4807-4957-9d48-f30bb5574c11\n",
            "Text: QLORAhas one low-precision storage data type, in our case\n",
            "usually 4-bit, and one computation data type that is usually BFloat16.\n",
            "In practice, this means whenever a QLORAweight tensor is used, we\n",
            "dequantize the tensor to BFloat16, and then perform a matrix\n",
            "multiplication in 16-bit. We now discuss the components of QL ORA\n",
            "followed by a formal defi...\n",
            "Score:  0.344\n",
            "\n",
            "Node 3: Node ID: e408c30c-c74b-4dc2-ac06-979166a339cd\n",
            "Text: Parameter Efficient Finetuning (PEFT) method, most of the memory\n",
            "footprint for LLM finetuning comes from activation gradients and not\n",
            "from the learned LoRA parameters. For a 7B LLaMA model trained on FLAN\n",
            "v2 with a batch size of 1, with LoRA weights equivalent to commonly\n",
            "used 0.2% of the original model weights[ 28,37], the LoRA input\n",
            "gradients ...\n",
            "Score:  0.341\n",
            "\n",
            "Node 4: Node ID: 3307edf4-dc70-416a-ab5d-a89f195828d9\n",
            "Text: QL ORA.Using the components described above, we define QLORAfor\n",
            "a single linear layer in the quantized base model with a single LoRA\n",
            "adapter as follows: YBF16=XBF16doubleDequant (cFP32 1, ck-bit 2,WNF4)\n",
            "+XBF16LBF16 1LBF16 2, (5) where doubleDequant (·)is defined as:\n",
            "doubleDequant (cFP32 1, ck-bit 2,Wk-bit) =dequant (dequant (cFP32 1,\n",
            "ck-bit 2),W...\n",
            "Score:  0.211\n",
            "\n",
            "Running Evaluation for Reranker: bge-reranker-large\n",
            "Visualize Retrieved Nodes for Reranker: bge-reranker-large\n",
            "Node 0: Node ID: 9e47c8b4-4807-4957-9d48-f30bb5574c11\n",
            "Text: QLORAhas one low-precision storage data type, in our case\n",
            "usually 4-bit, and one computation data type that is usually BFloat16.\n",
            "In practice, this means whenever a QLORAweight tensor is used, we\n",
            "dequantize the tensor to BFloat16, and then perform a matrix\n",
            "multiplication in 16-bit. We now discuss the components of QL ORA\n",
            "followed by a formal defi...\n",
            "Score:  0.226\n",
            "\n",
            "Node 1: Node ID: e408c30c-c74b-4dc2-ac06-979166a339cd\n",
            "Text: Parameter Efficient Finetuning (PEFT) method, most of the memory\n",
            "footprint for LLM finetuning comes from activation gradients and not\n",
            "from the learned LoRA parameters. For a 7B LLaMA model trained on FLAN\n",
            "v2 with a batch size of 1, with LoRA weights equivalent to commonly\n",
            "used 0.2% of the original model weights[ 28,37], the LoRA input\n",
            "gradients ...\n",
            "Score:  0.177\n",
            "\n",
            "Node 2: Node ID: f01414c7-87ee-4900-bfb2-808e93363b76\n",
            "Text: An additional limitation is that we did not evaluate different\n",
            "bit-precisions, such as using 3-bit base models, or different adapter\n",
            "methods. Besides LoRA, there is also a wide variety Parameter\n",
            "Efficient FineTuning (PEFT) methods that have been shown to work well.\n",
            "However, it is unclear if these methods scale to large models. We used\n",
            "LoRA as ma...\n",
            "Score:  0.170\n",
            "\n",
            "Node 3: Node ID: f30cd62a-c9fb-435d-a80b-e3674411ab00\n",
            "Text: QL ORA: Efficient Finetuning of Quantized LLMs Tim\n",
            "Dettmers∗Artidoro Pagnoni∗Ari Holtzman Luke Zettlemoyer University of\n",
            "Washington {dettmers,artidoro,ahai,lsz}@cs.washington.edu Abstract We\n",
            "present QLORA, an efficient finetuning approach that reduces memory\n",
            "us- age enough to finetune a 65B parameter model on a single 48GB GPU\n",
            "while preserving f...\n",
            "Score:  0.125\n",
            "\n",
            "Node 4: Node ID: 43662513-790f-4953-aaac-6d144c55509a\n",
            "Text: QLORAcan be seen as an equalizing factor that helps to close the\n",
            "resource gap between large corporations and small teams with consumer\n",
            "GPUs. Another potential source of impact is deployment to mobile\n",
            "phones. We believe our QLORAmethod might enable the critical milestone\n",
            "of enabling the finetuning of LLMs on phones and other low resource\n",
            "settings...\n",
            "Score:  0.105\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OQnVyOlUKA3A"
      },
      "id": "OQnVyOlUKA3A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_str = \"What are the benefits of using QLOra?\"\n",
        "\n",
        "# Function to validate and clean nodes\n",
        "def clean_nodes(nodes):\n",
        "    cleaned_nodes = []\n",
        "    for node in nodes:\n",
        "        if node.metadata is None:\n",
        "            node.metadata = {}\n",
        "        cleaned_nodes.append(node)\n",
        "    return cleaned_nodes\n",
        "\n",
        "# Loop over rerankers\n",
        "for rerank_name, reranker in RERANKERS.items():\n",
        "    print(f\"Running Evaluation for Reranker: {rerank_name}\")\n",
        "\n",
        "    query_bundle = QueryBundle(query_str)\n",
        "\n",
        "    retrieved_nodes = retriever.retrieve(query_bundle)\n",
        "\n",
        "    # Validate and clean retrieved nodes\n",
        "    retrieved_nodes = clean_nodes(retrieved_nodes)\n",
        "\n",
        "    if reranker != \"None\":\n",
        "        retrieved_nodes = reranker.postprocess_nodes(retrieved_nodes, query_bundle)\n",
        "        # Clean nodes again after reranking\n",
        "        retrieved_nodes = clean_nodes(retrieved_nodes)\n",
        "    else:\n",
        "        retrieved_nodes = clean_nodes(retrieved_nodes)\n",
        "\n",
        "    print(f\"Visualize Retrieved Nodes for Reranker: {rerank_name}\")\n",
        "    for idx, node in enumerate(retrieved_nodes):\n",
        "        print(f\"Node {idx}: {node}\")\n",
        "    # visualize_retrieved_nodes(retrieved_nodes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faAbohGGKA7n",
        "outputId": "a6ab30cf-0840-44cf-ab23-a77dc9a5b3a4"
      },
      "id": "faAbohGGKA7n",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Evaluation for Reranker: WithoutReranker\n",
            "Visualize Retrieved Nodes for Reranker: WithoutReranker\n",
            "Node 0: Node ID: 95e0b257-01d5-4ef2-a331-a9a04a229867\n",
            "Text: This second step yields the quantized quantization constants\n",
            "cFP8 2and the second level of quantization constants cFP32 1. We use\n",
            "8-bit Floats with a blocksize of 256 for the second quantization as no\n",
            "performance degradation is observed for 8-bit quantization, in line\n",
            "with results from Dettmers and Zettlemoyer [13]. Since the cFP32 2are\n",
            "positive...\n",
            "Score:  0.874\n",
            "\n",
            "Node 1: Node ID: 3307edf4-dc70-416a-ab5d-a89f195828d9\n",
            "Text: QL ORA.Using the components described above, we define QLORAfor\n",
            "a single linear layer in the quantized base model with a single LoRA\n",
            "adapter as follows: YBF16=XBF16doubleDequant (cFP32 1, ck-bit 2,WNF4)\n",
            "+XBF16LBF16 1LBF16 2, (5) where doubleDequant (·)is defined as:\n",
            "doubleDequant (cFP32 1, ck-bit 2,Wk-bit) =dequant (dequant (cFP32 1,\n",
            "ck-bit 2),W...\n",
            "Score:  0.874\n",
            "\n",
            "Node 2: Node ID: 43662513-790f-4953-aaac-6d144c55509a\n",
            "Text: QLORAcan be seen as an equalizing factor that helps to close the\n",
            "resource gap between large corporations and small teams with consumer\n",
            "GPUs. Another potential source of impact is deployment to mobile\n",
            "phones. We believe our QLORAmethod might enable the critical milestone\n",
            "of enabling the finetuning of LLMs on phones and other low resource\n",
            "settings...\n",
            "Score:  0.871\n",
            "\n",
            "Node 3: Node ID: 9e47c8b4-4807-4957-9d48-f30bb5574c11\n",
            "Text: QLORAhas one low-precision storage data type, in our case\n",
            "usually 4-bit, and one computation data type that is usually BFloat16.\n",
            "In practice, this means whenever a QLORAweight tensor is used, we\n",
            "dequantize the tensor to BFloat16, and then perform a matrix\n",
            "multiplication in 16-bit. We now discuss the components of QL ORA\n",
            "followed by a formal defi...\n",
            "Score:  0.870\n",
            "\n",
            "Node 4: Node ID: 168e43a0-faf6-4ca0-8b21-579b4313924b\n",
            "Text: Results for 7B LLaMA finetuning on Alpaca are shown in Figure 2.\n",
            "4-bit NormalFloat yields better performance than 4-bit Floating Point\n",
            "While the 4-bit NormalFloat (NF4) data type is information-\n",
            "theoretically optimal, it still needs to be determined if this\n",
            "property translates to empirical advantages. We follow the setup from\n",
            "Dettmers and Zettle...\n",
            "Score:  0.856\n",
            "\n",
            "Node 5: Node ID: e408c30c-c74b-4dc2-ac06-979166a339cd\n",
            "Text: Parameter Efficient Finetuning (PEFT) method, most of the memory\n",
            "footprint for LLM finetuning comes from activation gradients and not\n",
            "from the learned LoRA parameters. For a 7B LLaMA model trained on FLAN\n",
            "v2 with a batch size of 1, with LoRA weights equivalent to commonly\n",
            "used 0.2% of the original model weights[ 28,37], the LoRA input\n",
            "gradients ...\n",
            "Score:  0.854\n",
            "\n",
            "Node 6: Node ID: 2ff6bec1-82fe-4770-bbe5-dff7dca08d1d\n",
            "Text: Figure 1: Different finetuning methods and their memory\n",
            "requirements. QLORAimproves over LoRA by quantizing the transformer\n",
            "model to 4-bit precision and using paged optimizers to handle memory\n",
            "spikes. 2 Background Block-wise k-bit Quantization Quantization is the\n",
            "process of discretizing an input from a rep- resentation that holds\n",
            "more informatio...\n",
            "Score:  0.853\n",
            "\n",
            "Node 7: Node ID: e10f9653-feb0-47c4-b959-952b3d1a7908\n",
            "Text: ensure a discrete zeropoint of 0and to use all 2kbits for a\n",
            "k-bit datatype, we create an asymmetric data type by estimating the\n",
            "quantiles qiof two ranges qi:2k−1for the negative part and 2k−1+ 1for\n",
            "the positive part and then we unify these sets of qiand remove one of\n",
            "the two zeros that occurs in both sets. We term the resulting data\n",
            "type that ha...\n",
            "Score:  0.852\n",
            "\n",
            "Node 8: Node ID: 4ee9b304-5c1e-4b7e-9b8c-501f48d78d34\n",
            "Text: To this end, we finetune LLaMA 7B through 65B on two instruction\n",
            "following datasets, Alpaca and FLAN v2, and evaluate on the MMLU\n",
            "benchmark via 5-shot accuracy. Results are shown in Table 4 where we\n",
            "see that NF4 with double quantization fully recovers the 16-bit LoRA\n",
            "MMLU performance. In addition, we also note that QLORAwith FP4 lags\n",
            "behind the ...\n",
            "Score:  0.852\n",
            "\n",
            "Node 9: Node ID: f01414c7-87ee-4900-bfb2-808e93363b76\n",
            "Text: An additional limitation is that we did not evaluate different\n",
            "bit-precisions, such as using 3-bit base models, or different adapter\n",
            "methods. Besides LoRA, there is also a wide variety Parameter\n",
            "Efficient FineTuning (PEFT) methods that have been shown to work well.\n",
            "However, it is unclear if these methods scale to large models. We used\n",
            "LoRA as ma...\n",
            "Score:  0.851\n",
            "\n",
            "Running Evaluation for Reranker: CohereRerank\n",
            "Visualize Retrieved Nodes for Reranker: CohereRerank\n",
            "Node 0: Node ID: 43662513-790f-4953-aaac-6d144c55509a\n",
            "Text: QLORAcan be seen as an equalizing factor that helps to close the\n",
            "resource gap between large corporations and small teams with consumer\n",
            "GPUs. Another potential source of impact is deployment to mobile\n",
            "phones. We believe our QLORAmethod might enable the critical milestone\n",
            "of enabling the finetuning of LLMs on phones and other low resource\n",
            "settings...\n",
            "Score:  0.998\n",
            "\n",
            "Node 1: Node ID: f01414c7-87ee-4900-bfb2-808e93363b76\n",
            "Text: An additional limitation is that we did not evaluate different\n",
            "bit-precisions, such as using 3-bit base models, or different adapter\n",
            "methods. Besides LoRA, there is also a wide variety Parameter\n",
            "Efficient FineTuning (PEFT) methods that have been shown to work well.\n",
            "However, it is unclear if these methods scale to large models. We used\n",
            "LoRA as ma...\n",
            "Score:  0.994\n",
            "\n",
            "Node 2: Node ID: 3307edf4-dc70-416a-ab5d-a89f195828d9\n",
            "Text: QL ORA.Using the components described above, we define QLORAfor\n",
            "a single linear layer in the quantized base model with a single LoRA\n",
            "adapter as follows: YBF16=XBF16doubleDequant (cFP32 1, ck-bit 2,WNF4)\n",
            "+XBF16LBF16 1LBF16 2, (5) where doubleDequant (·)is defined as:\n",
            "doubleDequant (cFP32 1, ck-bit 2,Wk-bit) =dequant (dequant (cFP32 1,\n",
            "ck-bit 2),W...\n",
            "Score:  0.993\n",
            "\n",
            "Node 3: Node ID: 2ff6bec1-82fe-4770-bbe5-dff7dca08d1d\n",
            "Text: Figure 1: Different finetuning methods and their memory\n",
            "requirements. QLORAimproves over LoRA by quantizing the transformer\n",
            "model to 4-bit precision and using paged optimizers to handle memory\n",
            "spikes. 2 Background Block-wise k-bit Quantization Quantization is the\n",
            "process of discretizing an input from a rep- resentation that holds\n",
            "more informatio...\n",
            "Score:  0.992\n",
            "\n",
            "Node 4: Node ID: 4ee9b304-5c1e-4b7e-9b8c-501f48d78d34\n",
            "Text: To this end, we finetune LLaMA 7B through 65B on two instruction\n",
            "following datasets, Alpaca and FLAN v2, and evaluate on the MMLU\n",
            "benchmark via 5-shot accuracy. Results are shown in Table 4 where we\n",
            "see that NF4 with double quantization fully recovers the 16-bit LoRA\n",
            "MMLU performance. In addition, we also note that QLORAwith FP4 lags\n",
            "behind the ...\n",
            "Score:  0.992\n",
            "\n",
            "Running Evaluation for Reranker: bge-reranker-base\n",
            "Visualize Retrieved Nodes for Reranker: bge-reranker-base\n",
            "Node 0: Node ID: f01414c7-87ee-4900-bfb2-808e93363b76\n",
            "Text: An additional limitation is that we did not evaluate different\n",
            "bit-precisions, such as using 3-bit base models, or different adapter\n",
            "methods. Besides LoRA, there is also a wide variety Parameter\n",
            "Efficient FineTuning (PEFT) methods that have been shown to work well.\n",
            "However, it is unclear if these methods scale to large models. We used\n",
            "LoRA as ma...\n",
            "Score:  0.933\n",
            "\n",
            "Node 1: Node ID: 43662513-790f-4953-aaac-6d144c55509a\n",
            "Text: QLORAcan be seen as an equalizing factor that helps to close the\n",
            "resource gap between large corporations and small teams with consumer\n",
            "GPUs. Another potential source of impact is deployment to mobile\n",
            "phones. We believe our QLORAmethod might enable the critical milestone\n",
            "of enabling the finetuning of LLMs on phones and other low resource\n",
            "settings...\n",
            "Score:  0.895\n",
            "\n",
            "Node 2: Node ID: 168e43a0-faf6-4ca0-8b21-579b4313924b\n",
            "Text: Results for 7B LLaMA finetuning on Alpaca are shown in Figure 2.\n",
            "4-bit NormalFloat yields better performance than 4-bit Floating Point\n",
            "While the 4-bit NormalFloat (NF4) data type is information-\n",
            "theoretically optimal, it still needs to be determined if this\n",
            "property translates to empirical advantages. We follow the setup from\n",
            "Dettmers and Zettle...\n",
            "Score:  0.756\n",
            "\n",
            "Node 3: Node ID: e10f9653-feb0-47c4-b959-952b3d1a7908\n",
            "Text: ensure a discrete zeropoint of 0and to use all 2kbits for a\n",
            "k-bit datatype, we create an asymmetric data type by estimating the\n",
            "quantiles qiof two ranges qi:2k−1for the negative part and 2k−1+ 1for\n",
            "the positive part and then we unify these sets of qiand remove one of\n",
            "the two zeros that occurs in both sets. We term the resulting data\n",
            "type that ha...\n",
            "Score:  0.731\n",
            "\n",
            "Node 4: Node ID: 2ff6bec1-82fe-4770-bbe5-dff7dca08d1d\n",
            "Text: Figure 1: Different finetuning methods and their memory\n",
            "requirements. QLORAimproves over LoRA by quantizing the transformer\n",
            "model to 4-bit precision and using paged optimizers to handle memory\n",
            "spikes. 2 Background Block-wise k-bit Quantization Quantization is the\n",
            "process of discretizing an input from a rep- resentation that holds\n",
            "more informatio...\n",
            "Score:  0.511\n",
            "\n",
            "Running Evaluation for Reranker: bge-reranker-large\n",
            "Visualize Retrieved Nodes for Reranker: bge-reranker-large\n",
            "Node 0: Node ID: 43662513-790f-4953-aaac-6d144c55509a\n",
            "Text: QLORAcan be seen as an equalizing factor that helps to close the\n",
            "resource gap between large corporations and small teams with consumer\n",
            "GPUs. Another potential source of impact is deployment to mobile\n",
            "phones. We believe our QLORAmethod might enable the critical milestone\n",
            "of enabling the finetuning of LLMs on phones and other low resource\n",
            "settings...\n",
            "Score:  0.785\n",
            "\n",
            "Node 1: Node ID: f01414c7-87ee-4900-bfb2-808e93363b76\n",
            "Text: An additional limitation is that we did not evaluate different\n",
            "bit-precisions, such as using 3-bit base models, or different adapter\n",
            "methods. Besides LoRA, there is also a wide variety Parameter\n",
            "Efficient FineTuning (PEFT) methods that have been shown to work well.\n",
            "However, it is unclear if these methods scale to large models. We used\n",
            "LoRA as ma...\n",
            "Score:  0.711\n",
            "\n",
            "Node 2: Node ID: 4ee9b304-5c1e-4b7e-9b8c-501f48d78d34\n",
            "Text: To this end, we finetune LLaMA 7B through 65B on two instruction\n",
            "following datasets, Alpaca and FLAN v2, and evaluate on the MMLU\n",
            "benchmark via 5-shot accuracy. Results are shown in Table 4 where we\n",
            "see that NF4 with double quantization fully recovers the 16-bit LoRA\n",
            "MMLU performance. In addition, we also note that QLORAwith FP4 lags\n",
            "behind the ...\n",
            "Score:  0.472\n",
            "\n",
            "Node 3: Node ID: e408c30c-c74b-4dc2-ac06-979166a339cd\n",
            "Text: Parameter Efficient Finetuning (PEFT) method, most of the memory\n",
            "footprint for LLM finetuning comes from activation gradients and not\n",
            "from the learned LoRA parameters. For a 7B LLaMA model trained on FLAN\n",
            "v2 with a batch size of 1, with LoRA weights equivalent to commonly\n",
            "used 0.2% of the original model weights[ 28,37], the LoRA input\n",
            "gradients ...\n",
            "Score:  0.163\n",
            "\n",
            "Node 4: Node ID: 3307edf4-dc70-416a-ab5d-a89f195828d9\n",
            "Text: QL ORA.Using the components described above, we define QLORAfor\n",
            "a single linear layer in the quantized base model with a single LoRA\n",
            "adapter as follows: YBF16=XBF16doubleDequant (cFP32 1, ck-bit 2,WNF4)\n",
            "+XBF16LBF16 1LBF16 2, (5) where doubleDequant (·)is defined as:\n",
            "doubleDequant (cFP32 1, ck-bit 2,Wk-bit) =dequant (dequant (cFP32 1,\n",
            "ck-bit 2),W...\n",
            "Score:  0.086\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bgZ2Hq4EK_Na"
      },
      "id": "bgZ2Hq4EK_Na",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_str = \"What is QLoRA?\"\n",
        "\n",
        "# Function to validate and clean nodes\n",
        "def clean_nodes(nodes):\n",
        "    cleaned_nodes = []\n",
        "    for node in nodes:\n",
        "        if node.metadata is None:\n",
        "            node.metadata = {}\n",
        "        cleaned_nodes.append(node)\n",
        "    return cleaned_nodes\n",
        "\n",
        "# Loop over rerankers\n",
        "for rerank_name, reranker in RERANKERS.items():\n",
        "    print(f\"Running Evaluation for Reranker: {rerank_name}\")\n",
        "\n",
        "    query_bundle = QueryBundle(query_str)\n",
        "\n",
        "    retrieved_nodes = retriever.retrieve(query_bundle)\n",
        "\n",
        "    # Validate and clean retrieved nodes\n",
        "    retrieved_nodes = clean_nodes(retrieved_nodes)\n",
        "\n",
        "    if reranker != \"None\":\n",
        "        retrieved_nodes = reranker.postprocess_nodes(retrieved_nodes, query_bundle)\n",
        "        # Clean nodes again after reranking\n",
        "        retrieved_nodes = clean_nodes(retrieved_nodes)\n",
        "    else:\n",
        "        retrieved_nodes = clean_nodes(retrieved_nodes)\n",
        "\n",
        "    print(f\"Visualize Retrieved Nodes for Reranker: {rerank_name}\")\n",
        "    for idx, node in enumerate(retrieved_nodes):\n",
        "        print(f\"Node {idx}: {node}\")\n",
        "    # visualize_retrieved_nodes(retrieved_nodes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RulmhLGqKBAG",
        "outputId": "b0991776-1c90-4d5c-c270-f846991d4e1a"
      },
      "id": "RulmhLGqKBAG",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Evaluation for Reranker: WithoutReranker\n",
            "Visualize Retrieved Nodes for Reranker: WithoutReranker\n",
            "Node 0: Node ID: 9e47c8b4-4807-4957-9d48-f30bb5574c11\n",
            "Text: QLORAhas one low-precision storage data type, in our case\n",
            "usually 4-bit, and one computation data type that is usually BFloat16.\n",
            "In practice, this means whenever a QLORAweight tensor is used, we\n",
            "dequantize the tensor to BFloat16, and then perform a matrix\n",
            "multiplication in 16-bit. We now discuss the components of QL ORA\n",
            "followed by a formal defi...\n",
            "Score:  0.884\n",
            "\n",
            "Node 1: Node ID: 3307edf4-dc70-416a-ab5d-a89f195828d9\n",
            "Text: QL ORA.Using the components described above, we define QLORAfor\n",
            "a single linear layer in the quantized base model with a single LoRA\n",
            "adapter as follows: YBF16=XBF16doubleDequant (cFP32 1, ck-bit 2,WNF4)\n",
            "+XBF16LBF16 1LBF16 2, (5) where doubleDequant (·)is defined as:\n",
            "doubleDequant (cFP32 1, ck-bit 2,Wk-bit) =dequant (dequant (cFP32 1,\n",
            "ck-bit 2),W...\n",
            "Score:  0.876\n",
            "\n",
            "Node 2: Node ID: 2576d513-ff13-428f-8a70-ebba9a08c280\n",
            "Text: This calls for further investigations of the tradeoffs of simple\n",
            "cross-entropy loss and RLHF training. We hope that QLORA enables such\n",
            "analysis at scale, without the need for overwhelming computational\n",
            "resources. 7 Related Work Quantization of Large Language Models\n",
            "Quantization of LLMs has largely focused on quanti- zation for\n",
            "inference time. Ma...\n",
            "Score:  0.866\n",
            "\n",
            "Node 3: Node ID: 95e0b257-01d5-4ef2-a331-a9a04a229867\n",
            "Text: This second step yields the quantized quantization constants\n",
            "cFP8 2and the second level of quantization constants cFP32 1. We use\n",
            "8-bit Floats with a blocksize of 256 for the second quantization as no\n",
            "performance degradation is observed for 8-bit quantization, in line\n",
            "with results from Dettmers and Zettlemoyer [13]. Since the cFP32 2are\n",
            "positive...\n",
            "Score:  0.864\n",
            "\n",
            "Node 4: Node ID: 43662513-790f-4953-aaac-6d144c55509a\n",
            "Text: QLORAcan be seen as an equalizing factor that helps to close the\n",
            "resource gap between large corporations and small teams with consumer\n",
            "GPUs. Another potential source of impact is deployment to mobile\n",
            "phones. We believe our QLORAmethod might enable the critical milestone\n",
            "of enabling the finetuning of LLMs on phones and other low resource\n",
            "settings...\n",
            "Score:  0.864\n",
            "\n",
            "Node 5: Node ID: e408c30c-c74b-4dc2-ac06-979166a339cd\n",
            "Text: Parameter Efficient Finetuning (PEFT) method, most of the memory\n",
            "footprint for LLM finetuning comes from activation gradients and not\n",
            "from the learned LoRA parameters. For a 7B LLaMA model trained on FLAN\n",
            "v2 with a batch size of 1, with LoRA weights equivalent to commonly\n",
            "used 0.2% of the original model weights[ 28,37], the LoRA input\n",
            "gradients ...\n",
            "Score:  0.863\n",
            "\n",
            "Node 6: Node ID: 2ff6bec1-82fe-4770-bbe5-dff7dca08d1d\n",
            "Text: Figure 1: Different finetuning methods and their memory\n",
            "requirements. QLORAimproves over LoRA by quantizing the transformer\n",
            "model to 4-bit precision and using paged optimizers to handle memory\n",
            "spikes. 2 Background Block-wise k-bit Quantization Quantization is the\n",
            "process of discretizing an input from a rep- resentation that holds\n",
            "more informatio...\n",
            "Score:  0.856\n",
            "\n",
            "Node 7: Node ID: 2718ff40-fc67-4873-9a31-6efa0ba6c364\n",
            "Text: Table 1: Elo ratings for a competition between models, averaged\n",
            "for 10,000 random initial order- ings. The winner of a match is\n",
            "determined by GPT-4 which declares which response is better for a\n",
            "given prompt of the the Vicuna benchmark. 95% confidence intervals are\n",
            "shown ( ±). After GPT- 4, Guanaco 33B and 65B win the most matches,\n",
            "while Guanaco ...\n",
            "Score:  0.856\n",
            "\n",
            "Node 8: Node ID: f01414c7-87ee-4900-bfb2-808e93363b76\n",
            "Text: An additional limitation is that we did not evaluate different\n",
            "bit-precisions, such as using 3-bit base models, or different adapter\n",
            "methods. Besides LoRA, there is also a wide variety Parameter\n",
            "Efficient FineTuning (PEFT) methods that have been shown to work well.\n",
            "However, it is unclear if these methods scale to large models. We used\n",
            "LoRA as ma...\n",
            "Score:  0.854\n",
            "\n",
            "Node 9: Node ID: 7577350b-26af-4a14-be4d-3cdbb510d8bf\n",
            "Text: A QLoRA vs Standard Finetuning Experimental Setup Details A.1\n",
            "Hyperparameters for QL ORA We do a hyperparameter search for LoRA over\n",
            "the following variables: LoRA dropout { 0.0, 0.05, 0.1}, LoRA r{ 8,\n",
            "16, 32, 64, 128, 256}, LoRA layers {key+query, all attention layers,\n",
            "all FFN layers, all layers, attention + FFN output layers}. We keep\n",
            "LoRA αfix...\n",
            "Score:  0.850\n",
            "\n",
            "Running Evaluation for Reranker: CohereRerank\n",
            "Visualize Retrieved Nodes for Reranker: CohereRerank\n",
            "Node 0: Node ID: 3307edf4-dc70-416a-ab5d-a89f195828d9\n",
            "Text: QL ORA.Using the components described above, we define QLORAfor\n",
            "a single linear layer in the quantized base model with a single LoRA\n",
            "adapter as follows: YBF16=XBF16doubleDequant (cFP32 1, ck-bit 2,WNF4)\n",
            "+XBF16LBF16 1LBF16 2, (5) where doubleDequant (·)is defined as:\n",
            "doubleDequant (cFP32 1, ck-bit 2,Wk-bit) =dequant (dequant (cFP32 1,\n",
            "ck-bit 2),W...\n",
            "Score:  0.998\n",
            "\n",
            "Node 1: Node ID: 43662513-790f-4953-aaac-6d144c55509a\n",
            "Text: QLORAcan be seen as an equalizing factor that helps to close the\n",
            "resource gap between large corporations and small teams with consumer\n",
            "GPUs. Another potential source of impact is deployment to mobile\n",
            "phones. We believe our QLORAmethod might enable the critical milestone\n",
            "of enabling the finetuning of LLMs on phones and other low resource\n",
            "settings...\n",
            "Score:  0.998\n",
            "\n",
            "Node 2: Node ID: f01414c7-87ee-4900-bfb2-808e93363b76\n",
            "Text: An additional limitation is that we did not evaluate different\n",
            "bit-precisions, such as using 3-bit base models, or different adapter\n",
            "methods. Besides LoRA, there is also a wide variety Parameter\n",
            "Efficient FineTuning (PEFT) methods that have been shown to work well.\n",
            "However, it is unclear if these methods scale to large models. We used\n",
            "LoRA as ma...\n",
            "Score:  0.997\n",
            "\n",
            "Node 3: Node ID: 2ff6bec1-82fe-4770-bbe5-dff7dca08d1d\n",
            "Text: Figure 1: Different finetuning methods and their memory\n",
            "requirements. QLORAimproves over LoRA by quantizing the transformer\n",
            "model to 4-bit precision and using paged optimizers to handle memory\n",
            "spikes. 2 Background Block-wise k-bit Quantization Quantization is the\n",
            "process of discretizing an input from a rep- resentation that holds\n",
            "more informatio...\n",
            "Score:  0.997\n",
            "\n",
            "Node 4: Node ID: 2718ff40-fc67-4873-9a31-6efa0ba6c364\n",
            "Text: Table 1: Elo ratings for a competition between models, averaged\n",
            "for 10,000 random initial order- ings. The winner of a match is\n",
            "determined by GPT-4 which declares which response is better for a\n",
            "given prompt of the the Vicuna benchmark. 95% confidence intervals are\n",
            "shown ( ±). After GPT- 4, Guanaco 33B and 65B win the most matches,\n",
            "while Guanaco ...\n",
            "Score:  0.996\n",
            "\n",
            "Running Evaluation for Reranker: bge-reranker-base\n",
            "Visualize Retrieved Nodes for Reranker: bge-reranker-base\n",
            "Node 0: Node ID: f01414c7-87ee-4900-bfb2-808e93363b76\n",
            "Text: An additional limitation is that we did not evaluate different\n",
            "bit-precisions, such as using 3-bit base models, or different adapter\n",
            "methods. Besides LoRA, there is also a wide variety Parameter\n",
            "Efficient FineTuning (PEFT) methods that have been shown to work well.\n",
            "However, it is unclear if these methods scale to large models. We used\n",
            "LoRA as ma...\n",
            "Score:  0.489\n",
            "\n",
            "Node 1: Node ID: 3307edf4-dc70-416a-ab5d-a89f195828d9\n",
            "Text: QL ORA.Using the components described above, we define QLORAfor\n",
            "a single linear layer in the quantized base model with a single LoRA\n",
            "adapter as follows: YBF16=XBF16doubleDequant (cFP32 1, ck-bit 2,WNF4)\n",
            "+XBF16LBF16 1LBF16 2, (5) where doubleDequant (·)is defined as:\n",
            "doubleDequant (cFP32 1, ck-bit 2,Wk-bit) =dequant (dequant (cFP32 1,\n",
            "ck-bit 2),W...\n",
            "Score:  0.459\n",
            "\n",
            "Node 2: Node ID: 2ff6bec1-82fe-4770-bbe5-dff7dca08d1d\n",
            "Text: Figure 1: Different finetuning methods and their memory\n",
            "requirements. QLORAimproves over LoRA by quantizing the transformer\n",
            "model to 4-bit precision and using paged optimizers to handle memory\n",
            "spikes. 2 Background Block-wise k-bit Quantization Quantization is the\n",
            "process of discretizing an input from a rep- resentation that holds\n",
            "more informatio...\n",
            "Score:  0.261\n",
            "\n",
            "Node 3: Node ID: 43662513-790f-4953-aaac-6d144c55509a\n",
            "Text: QLORAcan be seen as an equalizing factor that helps to close the\n",
            "resource gap between large corporations and small teams with consumer\n",
            "GPUs. Another potential source of impact is deployment to mobile\n",
            "phones. We believe our QLORAmethod might enable the critical milestone\n",
            "of enabling the finetuning of LLMs on phones and other low resource\n",
            "settings...\n",
            "Score:  0.196\n",
            "\n",
            "Node 4: Node ID: 95e0b257-01d5-4ef2-a331-a9a04a229867\n",
            "Text: This second step yields the quantized quantization constants\n",
            "cFP8 2and the second level of quantization constants cFP32 1. We use\n",
            "8-bit Floats with a blocksize of 256 for the second quantization as no\n",
            "performance degradation is observed for 8-bit quantization, in line\n",
            "with results from Dettmers and Zettlemoyer [13]. Since the cFP32 2are\n",
            "positive...\n",
            "Score:  0.154\n",
            "\n",
            "Running Evaluation for Reranker: bge-reranker-large\n",
            "Visualize Retrieved Nodes for Reranker: bge-reranker-large\n",
            "Node 0: Node ID: f01414c7-87ee-4900-bfb2-808e93363b76\n",
            "Text: An additional limitation is that we did not evaluate different\n",
            "bit-precisions, such as using 3-bit base models, or different adapter\n",
            "methods. Besides LoRA, there is also a wide variety Parameter\n",
            "Efficient FineTuning (PEFT) methods that have been shown to work well.\n",
            "However, it is unclear if these methods scale to large models. We used\n",
            "LoRA as ma...\n",
            "Score:  0.440\n",
            "\n",
            "Node 1: Node ID: 43662513-790f-4953-aaac-6d144c55509a\n",
            "Text: QLORAcan be seen as an equalizing factor that helps to close the\n",
            "resource gap between large corporations and small teams with consumer\n",
            "GPUs. Another potential source of impact is deployment to mobile\n",
            "phones. We believe our QLORAmethod might enable the critical milestone\n",
            "of enabling the finetuning of LLMs on phones and other low resource\n",
            "settings...\n",
            "Score:  0.186\n",
            "\n",
            "Node 2: Node ID: 3307edf4-dc70-416a-ab5d-a89f195828d9\n",
            "Text: QL ORA.Using the components described above, we define QLORAfor\n",
            "a single linear layer in the quantized base model with a single LoRA\n",
            "adapter as follows: YBF16=XBF16doubleDequant (cFP32 1, ck-bit 2,WNF4)\n",
            "+XBF16LBF16 1LBF16 2, (5) where doubleDequant (·)is defined as:\n",
            "doubleDequant (cFP32 1, ck-bit 2,Wk-bit) =dequant (dequant (cFP32 1,\n",
            "ck-bit 2),W...\n",
            "Score:  0.181\n",
            "\n",
            "Node 3: Node ID: 9e47c8b4-4807-4957-9d48-f30bb5574c11\n",
            "Text: QLORAhas one low-precision storage data type, in our case\n",
            "usually 4-bit, and one computation data type that is usually BFloat16.\n",
            "In practice, this means whenever a QLORAweight tensor is used, we\n",
            "dequantize the tensor to BFloat16, and then perform a matrix\n",
            "multiplication in 16-bit. We now discuss the components of QL ORA\n",
            "followed by a formal defi...\n",
            "Score:  0.140\n",
            "\n",
            "Node 4: Node ID: 95e0b257-01d5-4ef2-a331-a9a04a229867\n",
            "Text: This second step yields the quantized quantization constants\n",
            "cFP8 2and the second level of quantization constants cFP32 1. We use\n",
            "8-bit Floats with a blocksize of 256 for the second quantization as no\n",
            "performance degradation is observed for 8-bit quantization, in line\n",
            "with results from Dettmers and Zettlemoyer [13]. Since the cFP32 2are\n",
            "positive...\n",
            "Score:  0.115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WakfA-LHKBDO"
      },
      "id": "WakfA-LHKBDO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aRC2_43Q_5WR"
      },
      "id": "aRC2_43Q_5WR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ctKGVm2k_5Zq"
      },
      "id": "ctKGVm2k_5Zq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_str = \"What are Paged Optimizers?\"\n",
        "\n",
        "results_df = pd.DataFrame()\n",
        "# Loop over rerankers\n",
        "for rerank_name, reranker in RERANKERS.items():\n",
        "    print(f\"Running Evaluation for Reranker: {rerank_name}\")\n",
        "\n",
        "    query_bundle = QueryBundle(query_str)\n",
        "\n",
        "    retrieved_nodes = retriever.retrieve(query_bundle)\n",
        "\n",
        "    if reranker != \"None\":\n",
        "      retrieved_nodes = reranker.postprocess_nodes(retrieved_nodes, query_bundle)\n",
        "    else:\n",
        "        retrieved_nodes\n",
        "\n",
        "    print(f\"Visualize Retrieved Nodes for Reranker: {rerank_name}\")\n",
        "    visualize_retrieved_nodes(retrieved_nodes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "VMWwweFPmRtQ",
        "outputId": "769d2286-a5c5-4257-ca6d-d5ad0d7eb916"
      },
      "id": "VMWwweFPmRtQ",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Evaluation for Reranker: WithoutReranker\n",
            "Visualize Retrieved Nodes for Reranker: WithoutReranker\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for TextNode\nmetadata\n  none is not an allowed value (type=type_error.none.not_allowed)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-0a41b1fbc524>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Visualize Retrieved Nodes for Reranker: {rerank_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mvisualize_retrieved_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrieved_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-6edc87d3ef67>\u001b[0m in \u001b[0;36mvisualize_retrieved_nodes\u001b[0;34m(nodes)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mnode_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mnode_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/v1/main.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknown_field\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_without_original_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0merror_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValidationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0merror_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                     \u001b[0mnew_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for TextNode\nmetadata\n  none is not an allowed value (type=type_error.none.not_allowed)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n",
        "\n",
        "Now, we will use RetrieverEvaluator to evaluate the quality of any Retriever module.\n",
        "\n",
        "We specify a set of different evaluation metrics: this includes hit-rate and MRR. For any given question, these will compare the quality of retrieved results from the ground-truth context.\n",
        "\n",
        "To ease the burden of creating the eval dataset in the first place, we can rely on synthetic data generation."
      ],
      "metadata": {
        "id": "C4Cd2heTnOX8"
      },
      "id": "C4Cd2heTnOX8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build an Evaluation dataset of (query, context) pairs\n",
        "Here we build a simple evaluation dataset over the existing text corpus.\n",
        "\n",
        "We use our generate_question_context_pairs to generate a set of (question, context) pairs over a given unstructured text corpus. This uses the LLM to auto-generate questions from each context chunk.\n",
        "\n",
        "We will use `Zephr-7B` LLM to generate Question-Context Pairs.\n",
        "\n",
        "We get back a EmbeddingQAFinetuneDataset object. At a high-level this contains a set of ids mapping to queries and relevant doc chunks, as well as the corpus itself."
      ],
      "metadata": {
        "id": "C3WuUf1aIG5p"
      },
      "id": "C3WuUf1aIG5p"
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt to generate questions\n",
        "qa_generate_prompt_tmpl = \"\"\"\\\n",
        "Context information is below.\n",
        "\n",
        "---------------------\n",
        "{context_str}\n",
        "---------------------\n",
        "\n",
        "Given the context information and not prior knowledge.\n",
        "generate only questions based on the below query.\n",
        "\n",
        "You are a Professor. Your task is to setup \\\n",
        "{num_questions_per_chunk} questions for an upcoming \\\n",
        "quiz/examination. The questions should be diverse in nature \\\n",
        "across the document. The questions should not contain options, not start with Q1/ Q2. \\\n",
        "Restrict the questions to the context information provided.\\\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "vSTU2FF2IJZ5"
      },
      "execution_count": 31,
      "outputs": [],
      "id": "vSTU2FF2IJZ5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluator\n",
        "from llama_index.core.evaluation import (\n",
        "    generate_question_context_pairs,\n",
        "    EmbeddingQAFinetuneDataset,\n",
        ")\n",
        "from llama_index.core.evaluation import RetrieverEvaluator\n",
        "\n",
        "qa_dataset = generate_question_context_pairs(\n",
        "    nodes, llm=llm, num_questions_per_chunk=2, qa_generate_prompt_tmpl=qa_generate_prompt_tmpl\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8q6NDTBHE1N",
        "outputId": "e179e12c-30d1-463b-aa77-cfe182c82ea9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/78 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  1%|▏         | 1/78 [00:09<12:10,  9.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  3%|▎         | 2/78 [00:14<08:54,  7.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  4%|▍         | 3/78 [00:22<09:02,  7.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  5%|▌         | 4/78 [00:30<09:13,  7.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  6%|▋         | 5/78 [00:37<09:03,  7.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  8%|▊         | 6/78 [00:44<08:49,  7.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  9%|▉         | 7/78 [00:51<08:26,  7.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 10%|█         | 8/78 [00:55<07:19,  6.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 12%|█▏        | 9/78 [01:02<07:24,  6.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 13%|█▎        | 10/78 [01:08<07:05,  6.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 14%|█▍        | 11/78 [01:14<06:50,  6.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 15%|█▌        | 12/78 [01:19<06:27,  5.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 17%|█▋        | 13/78 [01:24<06:04,  5.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 18%|█▊        | 14/78 [01:31<06:23,  5.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 19%|█▉        | 15/78 [01:37<06:14,  5.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 21%|██        | 16/78 [01:44<06:38,  6.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 22%|██▏       | 17/78 [01:51<06:39,  6.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 23%|██▎       | 18/78 [01:58<06:32,  6.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 24%|██▍       | 19/78 [02:06<06:54,  7.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 26%|██▌       | 20/78 [02:15<07:28,  7.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 27%|██▋       | 21/78 [02:36<11:02, 11.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 28%|██▊       | 22/78 [02:46<10:20, 11.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 29%|██▉       | 23/78 [02:54<09:20, 10.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 31%|███       | 24/78 [02:59<07:48,  8.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 32%|███▏      | 25/78 [03:07<07:26,  8.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 33%|███▎      | 26/78 [03:12<06:26,  7.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 35%|███▍      | 27/78 [03:19<06:15,  7.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 36%|███▌      | 28/78 [03:23<05:22,  6.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 37%|███▋      | 29/78 [03:33<05:56,  7.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 38%|███▊      | 30/78 [03:41<06:01,  7.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 40%|███▉      | 31/78 [03:48<05:46,  7.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 41%|████      | 32/78 [03:54<05:23,  7.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 42%|████▏     | 33/78 [04:02<05:34,  7.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 44%|████▎     | 34/78 [04:11<05:42,  7.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 45%|████▍     | 35/78 [04:18<05:20,  7.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 46%|████▌     | 36/78 [04:27<05:32,  7.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 47%|████▋     | 37/78 [04:31<04:43,  6.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 49%|████▊     | 38/78 [04:41<05:04,  7.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 50%|█████     | 39/78 [04:45<04:21,  6.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 51%|█████▏    | 40/78 [04:52<04:19,  6.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 53%|█████▎    | 41/78 [04:57<03:49,  6.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 54%|█████▍    | 42/78 [05:01<03:24,  5.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 55%|█████▌    | 43/78 [05:05<02:58,  5.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 56%|█████▋    | 44/78 [05:12<03:12,  5.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 58%|█████▊    | 45/78 [05:20<03:23,  6.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 59%|█████▉    | 46/78 [05:26<03:19,  6.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 60%|██████    | 47/78 [05:34<03:34,  6.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 62%|██████▏   | 48/78 [05:42<03:29,  7.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 63%|██████▎   | 49/78 [05:50<03:37,  7.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 64%|██████▍   | 50/78 [05:56<03:19,  7.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 65%|██████▌   | 51/78 [06:03<03:07,  6.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 67%|██████▋   | 52/78 [06:07<02:40,  6.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 68%|██████▊   | 53/78 [06:15<02:46,  6.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 69%|██████▉   | 54/78 [06:22<02:43,  6.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 71%|███████   | 55/78 [06:30<02:43,  7.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 72%|███████▏  | 56/78 [06:36<02:26,  6.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 73%|███████▎  | 57/78 [06:44<02:30,  7.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 74%|███████▍  | 58/78 [06:50<02:14,  6.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 76%|███████▌  | 59/78 [06:57<02:09,  6.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 77%|███████▋  | 60/78 [07:04<02:02,  6.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 78%|███████▊  | 61/78 [07:16<02:24,  8.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 79%|███████▉  | 62/78 [07:27<02:25,  9.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 81%|████████  | 63/78 [07:46<03:03, 12.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 82%|████████▏ | 64/78 [07:54<02:31, 10.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 83%|████████▎ | 65/78 [08:04<02:20, 10.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 85%|████████▍ | 66/78 [08:13<02:01, 10.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 86%|████████▌ | 67/78 [08:20<01:41,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 87%|████████▋ | 68/78 [08:27<01:24,  8.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 88%|████████▊ | 69/78 [08:33<01:09,  7.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 90%|████████▉ | 70/78 [08:39<00:57,  7.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 91%|█████████ | 71/78 [08:46<00:49,  7.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 92%|█████████▏| 72/78 [08:51<00:38,  6.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 94%|█████████▎| 73/78 [08:55<00:28,  5.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 95%|█████████▍| 74/78 [09:02<00:24,  6.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 96%|█████████▌| 75/78 [09:08<00:18,  6.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 97%|█████████▋| 76/78 [09:15<00:12,  6.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 99%|█████████▊| 77/78 [09:23<00:06,  6.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "100%|██████████| 78/78 [09:29<00:00,  7.31s/it]\n"
          ]
        }
      ],
      "id": "u8q6NDTBHE1N"
    },
    {
      "cell_type": "code",
      "source": [
        "len(qa_dataset.corpus.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeHlwMRTLxzT",
        "outputId": "5a550269-54a2-413f-abe1-6bc91b0b1019"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "id": "JeHlwMRTLxzT"
    },
    {
      "cell_type": "code",
      "source": [
        "qa_dataset.corpus.keys[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "ve4DU5mNGg4q",
        "outputId": "dbeda698-b15f-4f1f-d341-f84013a9f82d"
      },
      "id": "ve4DU5mNGg4q",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'builtin_function_or_method' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-c3e095bd2d51>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mqa_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generated 2 questions for this chunk\n",
        "qa_dataset.queries['297a0d1c-57d6-4b8b-928c-5c234cbcc02d']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "DmrmkCGYLDt4",
        "outputId": "935b4d71-eae5-473e-8203-18969b4dc547"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'297a0d1c-57d6-4b8b-928c-5c234cbcc02d'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-1b4fa7304f54>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generated 2 questions for this chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mqa_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'297a0d1c-57d6-4b8b-928c-5c234cbcc02d'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: '297a0d1c-57d6-4b8b-928c-5c234cbcc02d'"
          ]
        }
      ],
      "id": "DmrmkCGYLDt4"
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract relevant doc for this chunk\n",
        "qa_dataset.relevant_docs['297a0d1c-57d6-4b8b-928c-5c234cbcc02d']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "5d4PQwulLPdI",
        "outputId": "f6510e4c-a9df-48f2-bc27-1af1dcd864bb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'297a0d1c-57d6-4b8b-928c-5c234cbcc02d'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-66ecb1789412>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Extract relevant doc for this chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mqa_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelevant_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'297a0d1c-57d6-4b8b-928c-5c234cbcc02d'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: '297a0d1c-57d6-4b8b-928c-5c234cbcc02d'"
          ]
        }
      ],
      "id": "5d4PQwulLPdI"
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract corpus for this relevant doc\n",
        "qa_dataset.corpus['bc19a32b-006e-4ae2-98ea-6a20b7143f3c']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "AjWP8b9ILhnr",
        "outputId": "2cf19e4a-1efc-40d7-e5c3-49a0cae10129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Glue: A multi-\\ntask benchmark and analysis platform for natural language understanding. arXiv preprint\\narXiv:1804.07461 , 2018.\\n[59] Y . Wang, Y . Kordi, S. Mishra, A. Liu, N. A. Smith, D. Khashabi, and H. Hajishirzi. Self-instruct:\\nAligning language model with self generated instructions. arXiv preprint arXiv:2212.10560 ,\\n2022.\\n[60] Y . Wang, S. Mishra, P. Alipoormolabashi, Y . Kordi, A. Mirzaei, A. Arunkumar, A. Ashok, A. S.\\nDhanasekaran, A. Naik, D. Stap, et al. Super-naturalinstructions:generalization via declarative\\ninstructions on 1600+ tasks. In EMNLP , 2022.\\n[61] Y . Wang, S. Mishra, P. Alipoormolabashi, Y . Kordi, A. Mirzaei, A. Naik, A. Ashok, A. S.\\nDhanasekaran, A. Arunkumar, D. Stap, et al. Super-naturalinstructions: Generalization via\\ndeclarative instructions on 1600+ nlp tasks. In Proceedings of the 2022 Conference on Empirical\\nMethods in Natural Language Processing , pages 5085–5109, 2022.\\n[62] J. Wei, M. Bosma, V . Y . Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M. Dai, and Q. V . Le.\\nFinetuned language models are zero-shot learners. arXiv preprint arXiv:2109.01652 , 2021.\\n[63] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. H. Chi, Q. V . Le, D. Zhou, et al.\\nChain-of-thought prompting elicits reasoning in large language models. In Advances in Neural\\nInformation Processing Systems , 2022.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "id": "AjWP8b9ILhnr"
    },
    {
      "cell_type": "code",
      "source": [
        "# try it out on a sample query\n",
        "sample_id, sample_query = list(qa_dataset.queries.items())[1]\n",
        "sample_expected = qa_dataset.relevant_docs[sample_id]\n",
        "\n",
        "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
        "        [\"mrr\", \"hit_rate\"], retriever=retriever\n",
        "    )\n",
        "\n",
        "eval_result = retriever_evaluator.evaluate(sample_query, sample_expected)\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eO6ZMfxhnP5U",
        "outputId": "30d8a0f0-6f25-4038-d11f-5d48eac19995"
      },
      "id": "eO6ZMfxhnP5U",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What are the results of finetuning more than 1,000 models using QLORA, and how do they compare to previous SoTA models in terms of instruction following and chatbot performance? Additionally, what insights does QLORA provide regarding the trustworthiness of current chatbot benchmarks?\n",
            "Metrics: {'mrr': 0.5, 'hit_rate': 1.0}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try it out on an entire dataset"
      ],
      "metadata": {
        "id": "tbEATl1QpiZi"
      },
      "id": "tbEATl1QpiZi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a5533b3-eb9c-4628-b197-a23826178a84"
      },
      "source": [
        "### Define a function to display results"
      ],
      "id": "6a5533b3-eb9c-4628-b197-a23826178a84"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "1bdc5076-7806-4cec-a168-a18f1639a5b8"
      },
      "outputs": [],
      "source": [
        "def display_results(reranker_name, eval_results):\n",
        "    \"\"\"Display results from evaluate.\"\"\"\n",
        "\n",
        "    metric_dicts = []\n",
        "    for eval_result in eval_results:\n",
        "        metric_dict = eval_result.metric_vals_dict\n",
        "        metric_dicts.append(metric_dict)\n",
        "\n",
        "    full_df = pd.DataFrame(metric_dicts)\n",
        "\n",
        "    hit_rate = full_df[\"hit_rate\"].mean()\n",
        "    mrr = full_df[\"mrr\"].mean()\n",
        "\n",
        "    metric_df = pd.DataFrame({\"Reranker\": [reranker_name], \"hit_rate\": [hit_rate], \"mrr\": [mrr]})\n",
        "\n",
        "    return metric_df"
      ],
      "id": "1bdc5076-7806-4cec-a168-a18f1639a5b8"
    },
    {
      "cell_type": "code",
      "source": [
        "query_str = \"What are the top features of QLoRA?\"\n",
        "\n",
        "results_df = pd.DataFrame()\n",
        "# Loop over rerankers\n",
        "for rerank_name, reranker in RERANKERS.items():\n",
        "    print(f\"Running Evaluation for Reranker: {rerank_name}\")\n",
        "\n",
        "    query_bundle = QueryBundle(query_str)\n",
        "\n",
        "    retrieved_nodes = retriever.retrieve(query_bundle)\n",
        "\n",
        "    if reranker != \"None\":\n",
        "      retrieved_nodes = reranker.postprocess_nodes(retrieved_nodes, query_bundle)\n",
        "    else:\n",
        "        retrieved_nodes\n",
        "\n",
        "    retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
        "        [\"mrr\", \"hit_rate\"], retriever=retriever\n",
        "    )\n",
        "\n",
        "    eval_results = await retriever_evaluator.aevaluate_dataset(qa_dataset)\n",
        "\n",
        "    current_df = display_results(rerank_name, eval_results)\n",
        "    results_df = pd.concat([results_df, current_df], ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXOGHpuBOK-D",
        "outputId": "12c98777-96da-4d77-cf9f-16d3f888f0bd"
      },
      "id": "cXOGHpuBOK-D",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Evaluation for Reranker: WithoutReranker\n",
            "Running Evaluation for Reranker: CohereRerank\n",
            "Running Evaluation for Reranker: bge-reranker-base\n",
            "Running Evaluation for Reranker: bge-reranker-large\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df"
      ],
      "metadata": {
        "id": "lqrJx5aKjxvy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "ed9417e2-974a-4a2a-c5dd-4ed467346b9f"
      },
      "id": "lqrJx5aKjxvy",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Reranker  hit_rate       mrr\n",
              "0     WithoutReranker  0.916667  0.708794\n",
              "1        CohereRerank  0.916667  0.708794\n",
              "2   bge-reranker-base  0.916667  0.708794\n",
              "3  bge-reranker-large  0.916667  0.708794"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df664432-8643-46aa-993f-8f5992caf8b3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reranker</th>\n",
              "      <th>hit_rate</th>\n",
              "      <th>mrr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WithoutReranker</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.708794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CohereRerank</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.708794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bge-reranker-base</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.708794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bge-reranker-large</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.708794</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df664432-8643-46aa-993f-8f5992caf8b3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-df664432-8643-46aa-993f-8f5992caf8b3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-df664432-8643-46aa-993f-8f5992caf8b3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-74973d2b-9cfb-4d1f-8fb9-8b4c74d2edd8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-74973d2b-9cfb-4d1f-8fb9-8b4c74d2edd8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-74973d2b-9cfb-4d1f-8fb9-8b4c74d2edd8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5af91717-b48a-47dc-a9e3-eb0581d7ec0f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5af91717-b48a-47dc-a9e3-eb0581d7ec0f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Reranker\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"CohereRerank\",\n          \"bge-reranker-large\",\n          \"WithoutReranker\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hit_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.9166666666666666,\n        \"max\": 0.9166666666666666,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9166666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mrr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.7087937525437525,\n        \"max\": 0.7087937525437525,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7087937525437525\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# END"
      ],
      "metadata": {
        "id": "13hIvIwPnwwn"
      },
      "id": "13hIvIwPnwwn"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llama_index_v2",
      "language": "python",
      "name": "llama_index_v2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6cd91eb1f346430a97ac81b424652341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_466d746d756942368084109c946a1517",
              "IPY_MODEL_4257b45badd44a5eb8c13fcc137643bd",
              "IPY_MODEL_1108b8643bd440f3a79636e2c28e1a2f"
            ],
            "layout": "IPY_MODEL_c448eb1f10514b029cfd93638f453445"
          }
        },
        "466d746d756942368084109c946a1517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_780853b2806c4b8ba48c5148d5634149",
            "placeholder": "​",
            "style": "IPY_MODEL_ceb3aa94463f4f5a8a6efd88cde51d16",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "4257b45badd44a5eb8c13fcc137643bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f738edf27b954424b9cb859d087b44a6",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5fd61db1f8b414a8814c931d6529973",
            "value": 8
          }
        },
        "1108b8643bd440f3a79636e2c28e1a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86447ad506bc427597871bbdedc01039",
            "placeholder": "​",
            "style": "IPY_MODEL_df86f5a3b9944748b061ca9296f452d3",
            "value": " 8/8 [01:12&lt;00:00,  7.93s/it]"
          }
        },
        "c448eb1f10514b029cfd93638f453445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "780853b2806c4b8ba48c5148d5634149": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceb3aa94463f4f5a8a6efd88cde51d16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f738edf27b954424b9cb859d087b44a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5fd61db1f8b414a8814c931d6529973": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86447ad506bc427597871bbdedc01039": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df86f5a3b9944748b061ca9296f452d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8b5702cde8140598ce9c73c85599de8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d13a883472a4933888c0a2bf9170cf2",
              "IPY_MODEL_d0c2df989f3746f7b9b3d945cd5e8901",
              "IPY_MODEL_521e5438e02c436cb8a955eedd19a773"
            ],
            "layout": "IPY_MODEL_6a081b2a674545b1b9253873cf0424e9"
          }
        },
        "1d13a883472a4933888c0a2bf9170cf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1983243301a74b908f3af3ab791ad858",
            "placeholder": "​",
            "style": "IPY_MODEL_8f8a79d41bf845d3ab85c62d5ed7154b",
            "value": "config.json: 100%"
          }
        },
        "d0c2df989f3746f7b9b3d945cd5e8901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a51b59565294b4a90d8929b72227965",
            "max": 799,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a12c2ed09bc249a5b145fb2573850c58",
            "value": 799
          }
        },
        "521e5438e02c436cb8a955eedd19a773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b3eb63afbd540eaa9cf0403444545f3",
            "placeholder": "​",
            "style": "IPY_MODEL_f37892182d87496bb94dabb93d3c2d36",
            "value": " 799/799 [00:00&lt;00:00, 53.5kB/s]"
          }
        },
        "6a081b2a674545b1b9253873cf0424e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1983243301a74b908f3af3ab791ad858": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f8a79d41bf845d3ab85c62d5ed7154b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a51b59565294b4a90d8929b72227965": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a12c2ed09bc249a5b145fb2573850c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b3eb63afbd540eaa9cf0403444545f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f37892182d87496bb94dabb93d3c2d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c4c183a8f40471aa028480d317c5a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c11fbd2e1d44a4bbf7ce85efa9469a7",
              "IPY_MODEL_0b884583612c42e99d9337fb037c4118",
              "IPY_MODEL_61c6b26f7bc34791a299b91c2e311948"
            ],
            "layout": "IPY_MODEL_3af81d3617fe4ffb8b038b2ee87661cc"
          }
        },
        "8c11fbd2e1d44a4bbf7ce85efa9469a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_513bcc7c370240f6a30e75cee64f7977",
            "placeholder": "​",
            "style": "IPY_MODEL_ae54e97c5a704fb98f83ecc20df9d2b7",
            "value": "model.safetensors: 100%"
          }
        },
        "0b884583612c42e99d9337fb037c4118": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f8767799a194fe7852d981cd98d56f1",
            "max": 1112206140,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b35e7ea0d9e04a25926f43c848c3b71c",
            "value": 1112206140
          }
        },
        "61c6b26f7bc34791a299b91c2e311948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6b8306b6b0049d4b27cb7a1d5bdf3a7",
            "placeholder": "​",
            "style": "IPY_MODEL_0bcca2c260ce487caebbf978311bcc16",
            "value": " 1.11G/1.11G [00:10&lt;00:00, 248MB/s]"
          }
        },
        "3af81d3617fe4ffb8b038b2ee87661cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "513bcc7c370240f6a30e75cee64f7977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae54e97c5a704fb98f83ecc20df9d2b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f8767799a194fe7852d981cd98d56f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b35e7ea0d9e04a25926f43c848c3b71c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6b8306b6b0049d4b27cb7a1d5bdf3a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bcca2c260ce487caebbf978311bcc16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86c0b9a0dc0544e89f1c2fa4d19a2d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ffc3a4f10f84afd92b1d32f22c43da8",
              "IPY_MODEL_c3427192dbe64cf492c884b4dad2aa36",
              "IPY_MODEL_9e75eac4076744d6b3ce08b1f988ee5a"
            ],
            "layout": "IPY_MODEL_2225ac7b7eac40c1a4fca0a79f4325b1"
          }
        },
        "8ffc3a4f10f84afd92b1d32f22c43da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b35314aa37034005bf273a5012a32de2",
            "placeholder": "​",
            "style": "IPY_MODEL_9554e83fa9b946288bc9c247ccdddd38",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "c3427192dbe64cf492c884b4dad2aa36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08e9888223364bb3b3acd41fcdd37a74",
            "max": 443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b24116fbbb904e179f08875fa4399fad",
            "value": 443
          }
        },
        "9e75eac4076744d6b3ce08b1f988ee5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_164812204d91499898b08e96ff390774",
            "placeholder": "​",
            "style": "IPY_MODEL_e7d6d06eaef44baaa9f7b71a45e827aa",
            "value": " 443/443 [00:00&lt;00:00, 24.9kB/s]"
          }
        },
        "2225ac7b7eac40c1a4fca0a79f4325b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b35314aa37034005bf273a5012a32de2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9554e83fa9b946288bc9c247ccdddd38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08e9888223364bb3b3acd41fcdd37a74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b24116fbbb904e179f08875fa4399fad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "164812204d91499898b08e96ff390774": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7d6d06eaef44baaa9f7b71a45e827aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f2a7b332fec4d95b52518c02ba39374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4ec0c1e1ef242128e82e1b4d15752a5",
              "IPY_MODEL_747e87fc3b63481e92081e9dfd40579a",
              "IPY_MODEL_f5b4ef07b5c344e08749282eb777e91e"
            ],
            "layout": "IPY_MODEL_bf59aa0a707f456d8020ed6c0bb4985a"
          }
        },
        "a4ec0c1e1ef242128e82e1b4d15752a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5477792a46c457d9f96a8e2303f13c1",
            "placeholder": "​",
            "style": "IPY_MODEL_7f8c9ee6207d4620a4224bd177ed430f",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "747e87fc3b63481e92081e9dfd40579a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_100c18c7c3814d33a2217f80dc20d866",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a698ccf81c6b469b84e22d5a752fa849",
            "value": 5069051
          }
        },
        "f5b4ef07b5c344e08749282eb777e91e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17cd695ae88a45c6afb707087bc7c428",
            "placeholder": "​",
            "style": "IPY_MODEL_edfae701958f41098ee8156500d828f1",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 165MB/s]"
          }
        },
        "bf59aa0a707f456d8020ed6c0bb4985a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5477792a46c457d9f96a8e2303f13c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f8c9ee6207d4620a4224bd177ed430f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "100c18c7c3814d33a2217f80dc20d866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a698ccf81c6b469b84e22d5a752fa849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17cd695ae88a45c6afb707087bc7c428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edfae701958f41098ee8156500d828f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79171873c19040e580875e524204dea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b684c1b04b446cbbed227d4e4afd452",
              "IPY_MODEL_69407250b52d421a8c4c0c7bd24219cf",
              "IPY_MODEL_49beced1ee644cbb9c9dd44411758851"
            ],
            "layout": "IPY_MODEL_57eb33d0270a41d9865ac5e444e93a32"
          }
        },
        "8b684c1b04b446cbbed227d4e4afd452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c9236001b284c85aee46dfbbf060706",
            "placeholder": "​",
            "style": "IPY_MODEL_a2b729158c754a7a902b6b78715291b7",
            "value": "tokenizer.json: 100%"
          }
        },
        "69407250b52d421a8c4c0c7bd24219cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce24cdc70fde481e86071fd1caab9813",
            "max": 17098107,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c9eb001a181410fb93f3f11a616676d",
            "value": 17098107
          }
        },
        "49beced1ee644cbb9c9dd44411758851": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4066819993e4b96aa8f44eaaf6a0846",
            "placeholder": "​",
            "style": "IPY_MODEL_7df8d4294dcf40b8b38ccf68b4930807",
            "value": " 17.1M/17.1M [00:00&lt;00:00, 272MB/s]"
          }
        },
        "57eb33d0270a41d9865ac5e444e93a32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c9236001b284c85aee46dfbbf060706": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2b729158c754a7a902b6b78715291b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce24cdc70fde481e86071fd1caab9813": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c9eb001a181410fb93f3f11a616676d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4066819993e4b96aa8f44eaaf6a0846": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7df8d4294dcf40b8b38ccf68b4930807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "606f2bad18354d84a0c27bb1199f3a92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff64d8a5ca664c2a9e2f5509e548c015",
              "IPY_MODEL_63f50e8ee94a4d569714c018fa669b17",
              "IPY_MODEL_30fe51ce05c6488ca1d6054a285d6dca"
            ],
            "layout": "IPY_MODEL_86cc62ab92574385834347b7b24f559a"
          }
        },
        "ff64d8a5ca664c2a9e2f5509e548c015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c643f99cca64a7bb4582006e77a2bd2",
            "placeholder": "​",
            "style": "IPY_MODEL_0148c7b036b74af6aa7ad7d7785229d7",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "63f50e8ee94a4d569714c018fa669b17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ec85ff2fd284676831a2210c0999b55",
            "max": 279,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0da6ebf910b54ed4bf8e7e5f4ebf4cc7",
            "value": 279
          }
        },
        "30fe51ce05c6488ca1d6054a285d6dca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d11f79442a9a4a3f9b04a28fbc11b01d",
            "placeholder": "​",
            "style": "IPY_MODEL_d905ffe85a7e4e568205aed7296289cb",
            "value": " 279/279 [00:00&lt;00:00, 15.6kB/s]"
          }
        },
        "86cc62ab92574385834347b7b24f559a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c643f99cca64a7bb4582006e77a2bd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0148c7b036b74af6aa7ad7d7785229d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ec85ff2fd284676831a2210c0999b55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0da6ebf910b54ed4bf8e7e5f4ebf4cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d11f79442a9a4a3f9b04a28fbc11b01d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d905ffe85a7e4e568205aed7296289cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad6eef18310d4717b64d153856fb7e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b1be45b68f546ffa0d2c226ecd9f3a6",
              "IPY_MODEL_1710e88ceefc4d078225bcec8e8a7e98",
              "IPY_MODEL_59ff7cb07a064a04928fa3cae4407f01"
            ],
            "layout": "IPY_MODEL_34efbc0dd59f4dd288ae67766c859c52"
          }
        },
        "6b1be45b68f546ffa0d2c226ecd9f3a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f2b611c1ae0428ca5351ca0a582c832",
            "placeholder": "​",
            "style": "IPY_MODEL_f49bb7987c88474ea102c02687cc7bd4",
            "value": "config.json: 100%"
          }
        },
        "1710e88ceefc4d078225bcec8e8a7e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecd14d0567e04020ac5630e77e0ba622",
            "max": 801,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_237786aa999d43479d08e55a3f7c37a7",
            "value": 801
          }
        },
        "59ff7cb07a064a04928fa3cae4407f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62e1910678404be39d65507aefb4a579",
            "placeholder": "​",
            "style": "IPY_MODEL_33bbcbb393eb489488cd6de8e98e0090",
            "value": " 801/801 [00:00&lt;00:00, 47.9kB/s]"
          }
        },
        "34efbc0dd59f4dd288ae67766c859c52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f2b611c1ae0428ca5351ca0a582c832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f49bb7987c88474ea102c02687cc7bd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecd14d0567e04020ac5630e77e0ba622": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "237786aa999d43479d08e55a3f7c37a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62e1910678404be39d65507aefb4a579": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33bbcbb393eb489488cd6de8e98e0090": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab9b6001d5704afe8e96fa1072ccb42b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c0f507418054355b3d31b31b5980caf",
              "IPY_MODEL_2671e58e93b446ec995ca1fa735fcd22",
              "IPY_MODEL_280a8e8fc6544d3292c2767acb7d4a12"
            ],
            "layout": "IPY_MODEL_cd3d4b4e5ae84b5db2111d9e503ddf7d"
          }
        },
        "8c0f507418054355b3d31b31b5980caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56e7869ed4354237b7435fdefac71461",
            "placeholder": "​",
            "style": "IPY_MODEL_4166f2a005714a868c26f0d10ce507ba",
            "value": "model.safetensors: 100%"
          }
        },
        "2671e58e93b446ec995ca1fa735fcd22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b57ba63c10e43a6a856b14caae0fe44",
            "max": 2239618772,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e331768dd150484ab2dfc387268f0c8d",
            "value": 2239618772
          }
        },
        "280a8e8fc6544d3292c2767acb7d4a12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65798d204ec54b589cf777236d12f909",
            "placeholder": "​",
            "style": "IPY_MODEL_06fc346daeac4e5bbf46c5abc9c67263",
            "value": " 2.24G/2.24G [00:20&lt;00:00, 159MB/s]"
          }
        },
        "cd3d4b4e5ae84b5db2111d9e503ddf7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56e7869ed4354237b7435fdefac71461": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4166f2a005714a868c26f0d10ce507ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b57ba63c10e43a6a856b14caae0fe44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e331768dd150484ab2dfc387268f0c8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65798d204ec54b589cf777236d12f909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06fc346daeac4e5bbf46c5abc9c67263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adddc443c55c490aa1fac0a1dc2c2e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9aa3d3bbaaa04940a27844fc66e9cf60",
              "IPY_MODEL_d5c4e5475ed248d3a23b1a0b56a0a7d3",
              "IPY_MODEL_a0260b9f2b1b4bafb66bda19b9e245ea"
            ],
            "layout": "IPY_MODEL_9ae0ae52878947f699187cf1a745a8b6"
          }
        },
        "9aa3d3bbaaa04940a27844fc66e9cf60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1aed6cce195a4752a089b2c305e1d8ce",
            "placeholder": "​",
            "style": "IPY_MODEL_7d5e4b4d06c841ed8dcd959b706de012",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d5c4e5475ed248d3a23b1a0b56a0a7d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e8d2a184be7466c9db428061062506d",
            "max": 443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d04085c2e1241a7b6df4ea8a15c877d",
            "value": 443
          }
        },
        "a0260b9f2b1b4bafb66bda19b9e245ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ec97a247a8846e3a34ab730319c9e2e",
            "placeholder": "​",
            "style": "IPY_MODEL_c5f3577fa52d4b39bbf12a2d1d777825",
            "value": " 443/443 [00:00&lt;00:00, 21.4kB/s]"
          }
        },
        "9ae0ae52878947f699187cf1a745a8b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aed6cce195a4752a089b2c305e1d8ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d5e4b4d06c841ed8dcd959b706de012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e8d2a184be7466c9db428061062506d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d04085c2e1241a7b6df4ea8a15c877d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ec97a247a8846e3a34ab730319c9e2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5f3577fa52d4b39bbf12a2d1d777825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2748a653ad2c4c57b6c350e83001965a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15b91e39c2ff45c084d2296b847655bf",
              "IPY_MODEL_9444d49b94f44f7e885379dd3b4579be",
              "IPY_MODEL_fd2094d9a20a40458e0c3416b65480f8"
            ],
            "layout": "IPY_MODEL_4b9aac73477b45c6b1bd83eadf9095b7"
          }
        },
        "15b91e39c2ff45c084d2296b847655bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d744f9661f3f4a0aa96b6269b89b5b8e",
            "placeholder": "​",
            "style": "IPY_MODEL_e6b82c8687f64b8abe7e18d80260ff1c",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "9444d49b94f44f7e885379dd3b4579be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ee15f468d2e49b0a0b7d6940e057f7b",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1dcfd55096e04bf58144ef4616256ad1",
            "value": 5069051
          }
        },
        "fd2094d9a20a40458e0c3416b65480f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82e599fd460d4ba1afeeb60a9901be58",
            "placeholder": "​",
            "style": "IPY_MODEL_4673c726899c446583e8c5313c2bd494",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 83.1MB/s]"
          }
        },
        "4b9aac73477b45c6b1bd83eadf9095b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d744f9661f3f4a0aa96b6269b89b5b8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6b82c8687f64b8abe7e18d80260ff1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ee15f468d2e49b0a0b7d6940e057f7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dcfd55096e04bf58144ef4616256ad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82e599fd460d4ba1afeeb60a9901be58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4673c726899c446583e8c5313c2bd494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18225f843322455cbfadfb3926f0df72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f510bcc96c7e4413b31d0262217cc392",
              "IPY_MODEL_2dc1d04f6f20458a931ae4f7a9913fee",
              "IPY_MODEL_2f130a82737d459880b49fd6868332df"
            ],
            "layout": "IPY_MODEL_6326694600054549a36232183e2cee18"
          }
        },
        "f510bcc96c7e4413b31d0262217cc392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_621e249dd863495cb5d88c44f9919f2d",
            "placeholder": "​",
            "style": "IPY_MODEL_44e637d4bb394305ab2a4ed9b7f260b2",
            "value": "tokenizer.json: 100%"
          }
        },
        "2dc1d04f6f20458a931ae4f7a9913fee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d37ae8a0b8ff44ba9435e85ee12a0d34",
            "max": 17098107,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56bbbf97c7424aa79ae1f6ec513d8fdb",
            "value": 17098107
          }
        },
        "2f130a82737d459880b49fd6868332df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e46cedd83cef40d58b6229c27d924bf2",
            "placeholder": "​",
            "style": "IPY_MODEL_d90c2fbdb6ed400cbef6e355fa77290e",
            "value": " 17.1M/17.1M [00:00&lt;00:00, 208MB/s]"
          }
        },
        "6326694600054549a36232183e2cee18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "621e249dd863495cb5d88c44f9919f2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44e637d4bb394305ab2a4ed9b7f260b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d37ae8a0b8ff44ba9435e85ee12a0d34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56bbbf97c7424aa79ae1f6ec513d8fdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e46cedd83cef40d58b6229c27d924bf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d90c2fbdb6ed400cbef6e355fa77290e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "268381e8055a4b79a1faf91e6f6254f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a533fcb0fe7b4f4aa96ea2f1b3e92fde",
              "IPY_MODEL_f28e5b45e9614ac984d665aaeb2778e1",
              "IPY_MODEL_76a6fd497a57449f934f18d7b46a245a"
            ],
            "layout": "IPY_MODEL_68016e2fc2334e918a726530bd55e0a0"
          }
        },
        "a533fcb0fe7b4f4aa96ea2f1b3e92fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bc9ef7863dc4502ab4abec128a769c2",
            "placeholder": "​",
            "style": "IPY_MODEL_0bc811d59c374d3a93f80cd1a67be92a",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "f28e5b45e9614ac984d665aaeb2778e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbb7d85b43ef48f3a2ed6e31ccb3c9cd",
            "max": 279,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7669aad1d1f84a27b55deaf01fed88c3",
            "value": 279
          }
        },
        "76a6fd497a57449f934f18d7b46a245a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd7bf50fea2f471b9b07afa111e96994",
            "placeholder": "​",
            "style": "IPY_MODEL_657ca0cf84c04a4fadad8d7ec4c20aae",
            "value": " 279/279 [00:00&lt;00:00, 20.8kB/s]"
          }
        },
        "68016e2fc2334e918a726530bd55e0a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bc9ef7863dc4502ab4abec128a769c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bc811d59c374d3a93f80cd1a67be92a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbb7d85b43ef48f3a2ed6e31ccb3c9cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7669aad1d1f84a27b55deaf01fed88c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd7bf50fea2f471b9b07afa111e96994": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "657ca0cf84c04a4fadad8d7ec4c20aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}